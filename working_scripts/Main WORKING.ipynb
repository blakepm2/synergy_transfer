{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import time\n",
    "import pickle\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities import Mapping\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='data/'\n",
    "save_path='save/'\n",
    "\n",
    "bsz=128\n",
    "cuda=True\n",
    "device=0\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "num_gene_compressed_drug=64\n",
    "num_gene_compressed_cell=128\n",
    "\n",
    "#isClassification=True #False for regression task\n",
    "syn_threshold=30\n",
    "ri_threshold=50\n",
    "\n",
    "log_interval=100\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drug pair, cell, scoers\n",
    "df=pickle.load(open(data_path+'summary_mean.p', 'rb'))\n",
    "codes=pickle.load(open(data_path+'codes.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug_row</th>\n",
       "      <th>drug_col</th>\n",
       "      <th>cell_line_name</th>\n",
       "      <th>study_id</th>\n",
       "      <th>ri_row</th>\n",
       "      <th>ri_col</th>\n",
       "      <th>synergy_loewe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3865</td>\n",
       "      <td>705</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-21.0794</td>\n",
       "      <td>17.392589</td>\n",
       "      <td>4.436431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3817</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-20.0430</td>\n",
       "      <td>25.595000</td>\n",
       "      <td>-44.555935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3817</td>\n",
       "      <td>432</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-9.7760</td>\n",
       "      <td>29.111000</td>\n",
       "      <td>-37.189720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.7970</td>\n",
       "      <td>6.964000</td>\n",
       "      <td>1.283298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>218</td>\n",
       "      <td>218</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.5280</td>\n",
       "      <td>7.190000</td>\n",
       "      <td>-3.028745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   drug_row  drug_col  cell_line_name  study_id   ri_row     ri_col  \\\n",
       "0      3865       705               0       4.0 -21.0794  17.392589   \n",
       "1      3817       218               1       6.0 -20.0430  25.595000   \n",
       "2      3817       432               1       6.0  -9.7760  29.111000   \n",
       "3       218       218               2      12.0   6.7970   6.964000   \n",
       "4       218       218               3      12.0  11.5280   7.190000   \n",
       "\n",
       "   synergy_loewe  \n",
       "0       4.436431  \n",
       "1     -44.555935  \n",
       "2     -37.189720  \n",
       "3       1.283298  \n",
       "4      -3.028745  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug's external features\n",
    "drug_features=pickle.load(open(data_path+'drug_features.p', 'rb'))\n",
    "# drug_features = pd.read_csv(data_path+'drug_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>fps</th>\n",
       "      <th>gene_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[47, 27, 1, 4, 13, 30, 47, 31, 30, 47, 31, 47,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[10256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[47, 1, 6, 47, 20, 47, 30, 47, 30, 20, 1, 6, 3...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[7880]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[47, 6, 47, 1, 30, 47, 47, 1, 6, 47, 47, 47, 1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[47, 47, 30, 47, 31, 47, 47, 6, 47, 1, 17, 47,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[22597, 3305, 16393, 5169, 1613]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[47, 47, 6, 47, 20, 47, 47, 20, 47, 30, 47, 30...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>[47, 1, 30, 47, 31, 47, 47, 20, 47, 47, 30, 20...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1769]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>[47, 47, 30, 47, 6, 20, 47, 47, 20, 47, 47, 20...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>[47, 6, 47, 1, 30, 47, 27, 47, 16, 16, 10, 13,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>[47, 6, 47, 15, 47, 47, 47, 6, 47, 1, 47, 30, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[10151]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>[47, 47, 1, 30, 47, 31, 47, 30, 20, 15, 31, 15...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[14781, 15181, 22469]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4149 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles  \\\n",
       "id                                                        \n",
       "0     [47, 27, 1, 4, 13, 30, 47, 31, 30, 47, 31, 47,...   \n",
       "1     [47, 1, 6, 47, 20, 47, 30, 47, 30, 20, 1, 6, 3...   \n",
       "2     [47, 6, 47, 1, 30, 47, 47, 1, 6, 47, 47, 47, 1...   \n",
       "3     [47, 47, 30, 47, 31, 47, 47, 6, 47, 1, 17, 47,...   \n",
       "4     [47, 47, 6, 47, 20, 47, 47, 20, 47, 30, 47, 30...   \n",
       "...                                                 ...   \n",
       "4144  [47, 1, 30, 47, 31, 47, 47, 20, 47, 47, 30, 20...   \n",
       "4145  [47, 47, 30, 47, 6, 20, 47, 47, 20, 47, 47, 20...   \n",
       "4146  [47, 6, 47, 1, 30, 47, 27, 47, 16, 16, 10, 13,...   \n",
       "4147  [47, 6, 47, 15, 47, 47, 47, 6, 47, 1, 47, 30, ...   \n",
       "4148  [47, 47, 1, 30, 47, 31, 47, 30, 20, 15, 31, 15...   \n",
       "\n",
       "                                                    fps  \\\n",
       "id                                                        \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "4144  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4145  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4146  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4147  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4148  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                               gene_id  \n",
       "id                                      \n",
       "0                              [10256]  \n",
       "1                               [7880]  \n",
       "2                                   []  \n",
       "3     [22597, 3305, 16393, 5169, 1613]  \n",
       "4                                   []  \n",
       "...                                ...  \n",
       "4144                            [1769]  \n",
       "4145                                []  \n",
       "4146                                []  \n",
       "4147                           [10151]  \n",
       "4148             [14781, 15181, 22469]  \n",
       "\n",
       "[4149 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell's external features\n",
    "cell_features=pickle.load(open(data_path+'cell_features.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_celllines= len(codes['cell'].idx2item)\n",
    "num_drugs=len(codes['drugs'].idx2item)\n",
    "\n",
    "num_genes = len(codes['gene'].idx2item)\n",
    "num_tissue = len(codes['tissue'].idx2item)\n",
    "num_disease = len(codes['disease'].idx2item)\n",
    "\n",
    "num_drug_fp=len(drug_features.loc[0,'fps'])\n",
    "max_drug_sm_len = drug_features['smiles'].apply(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugTargetDataset(Dataset):\n",
    "    def __init__(self, drug_features):\n",
    "        self.drug_features = drug_features\n",
    "    def __len__(self):\n",
    "        return len(self.drug_features)\n",
    "    def __getitem__(self,idx):\n",
    "        gene_ids=self.drug_features.loc[idx, 'gene_id']\n",
    "        genes=np.zeros(num_genes)\n",
    "        genes[gene_ids]=1\n",
    "        \n",
    "        return genes\n",
    "\n",
    "# class DrugTargetDataset(Dataset):\n",
    "#     def __init__(self, drug_features):\n",
    "#         self.drug_features = drug_features\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.drug_features)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if idx not in self.drug_features.index:\n",
    "#             gene_ids = self.drug_features.loc[idx-1, 'gene_id']\n",
    "#             genes = np.zeros(num_genes)\n",
    "#             genes[gene_ids] = 1\n",
    "#             return genes\n",
    "\n",
    "#         try:\n",
    "#             gene_ids = self.drug_features.loc[idx, 'gene_id']\n",
    "#             genes = np.zeros(num_genes)\n",
    "#             genes[gene_ids] = 1\n",
    "#             return genes\n",
    "#         except KeyError as e:\n",
    "#             print(f\"Skipping index {idx} due to KeyError: {e}\")\n",
    "#             return None  # Return None or consider raising an exception\n",
    "\n",
    "    \n",
    "class CellGeneDataset(Dataset):\n",
    "    def __init__(self, cell_features):\n",
    "        self.cell_features = cell_features\n",
    "    def __len__(self):\n",
    "        return len(self.cell_features)\n",
    "    def __getitem__(self,idx):\n",
    "        gene_ids=self.cell_features.loc[idx,'gene_id']\n",
    "        genes = np.zeros(num_genes)\n",
    "        for key,value in gene_ids.items():\n",
    "            genes[key]=value\n",
    "            \n",
    "        return genes\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_target_dataset = DrugTargetDataset(drug_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>fps</th>\n",
       "      <th>gene_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[47, 27, 1, 4, 13, 30, 47, 31, 30, 47, 31, 47,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[10256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[47, 1, 6, 47, 20, 47, 30, 47, 30, 20, 1, 6, 3...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[7880]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[47, 6, 47, 1, 30, 47, 47, 1, 6, 47, 47, 47, 1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[47, 47, 30, 47, 31, 47, 47, 6, 47, 1, 17, 47,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[22597, 3305, 16393, 5169, 1613]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[47, 47, 6, 47, 20, 47, 47, 20, 47, 30, 47, 30...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>[47, 1, 30, 47, 31, 47, 47, 20, 47, 47, 30, 20...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1769]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>[47, 47, 30, 47, 6, 20, 47, 47, 20, 47, 47, 20...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>[47, 6, 47, 1, 30, 47, 27, 47, 16, 16, 10, 13,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>[47, 6, 47, 15, 47, 47, 47, 6, 47, 1, 47, 30, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[10151]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>[47, 47, 1, 30, 47, 31, 47, 30, 20, 15, 31, 15...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[14781, 15181, 22469]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4149 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles  \\\n",
       "id                                                        \n",
       "0     [47, 27, 1, 4, 13, 30, 47, 31, 30, 47, 31, 47,...   \n",
       "1     [47, 1, 6, 47, 20, 47, 30, 47, 30, 20, 1, 6, 3...   \n",
       "2     [47, 6, 47, 1, 30, 47, 47, 1, 6, 47, 47, 47, 1...   \n",
       "3     [47, 47, 30, 47, 31, 47, 47, 6, 47, 1, 17, 47,...   \n",
       "4     [47, 47, 6, 47, 20, 47, 47, 20, 47, 30, 47, 30...   \n",
       "...                                                 ...   \n",
       "4144  [47, 1, 30, 47, 31, 47, 47, 20, 47, 47, 30, 20...   \n",
       "4145  [47, 47, 30, 47, 6, 20, 47, 47, 20, 47, 47, 20...   \n",
       "4146  [47, 6, 47, 1, 30, 47, 27, 47, 16, 16, 10, 13,...   \n",
       "4147  [47, 6, 47, 15, 47, 47, 47, 6, 47, 1, 47, 30, ...   \n",
       "4148  [47, 47, 1, 30, 47, 31, 47, 30, 20, 15, 31, 15...   \n",
       "\n",
       "                                                    fps  \\\n",
       "id                                                        \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "4144  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4145  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4146  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4147  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4148  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                               gene_id  \n",
       "id                                      \n",
       "0                              [10256]  \n",
       "1                               [7880]  \n",
       "2                                   []  \n",
       "3     [22597, 3305, 16393, 5169, 1613]  \n",
       "4                                   []  \n",
       "...                                ...  \n",
       "4144                            [1769]  \n",
       "4145                                []  \n",
       "4146                                []  \n",
       "4147                           [10151]  \n",
       "4148             [14781, 15181, 22469]  \n",
       "\n",
       "[4149 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drug_target_dataset[2115]\n",
    "# drug_features.iloc[2114]\n",
    "# drug_target_dataset[3904]\n",
    "drug_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two layers of fully connected layers\n",
    "class FC2(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout):\n",
    "        super(FC2, self).__init__()\n",
    "        \n",
    "        self.bn = nn.BatchNorm1d(in_features)\n",
    "        self.fc1 = nn.Linear(in_features, int(in_features/2))\n",
    "        self.fc2 = nn.Linear(int(in_features/2),out_features)\n",
    "        self.dropout= nn.Dropout(dropout)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress gene features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneCompressor(nn.Module):\n",
    "    def __init__(self, num_in, num_out, dropout=0.1):\n",
    "        super(GeneCompressor, self).__init__()\n",
    "        self.dropout=dropout\n",
    "        self.encoder=nn.Linear(num_in, num_out)\n",
    "        self.decoder=nn.Linear(num_out,num_in)\n",
    "\n",
    "    def _encoder(self,x):\n",
    "        return F.dropout(F.relu(self.encoder(x)), self.dropout, training=self.training)\n",
    "    \n",
    "    def _decoder(self,x):\n",
    "        return F.dropout(self.decoder(x), self.dropout, training=self.training)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self._encoder(x)\n",
    "        x=self._decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def geneCompressing(data_loader, num_gene_compressed, noise_weight=0.2, epochs=20, log_interval=10):\n",
    "#     geneCompressor = GeneCompressor(num_genes, num_out=num_gene_compressed, dropout=0.1)\n",
    "#     if cuda:\n",
    "#         geneCompressor = geneCompressor.cuda()\n",
    "#     criterion = nn.MSELoss()\n",
    "#     optimizer = optim.Adam(geneCompressor.parameters())\n",
    "\n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         geneCompressor.train()\n",
    "#         total_loss = 0\n",
    "#         start_time = time.time()\n",
    "#         for iteration, gene in enumerate(data_loader):\n",
    "#             try:\n",
    "#                 gene = Variable(gene).float()\n",
    "#                 noise = noise_weight * torch.randn(gene.shape)\n",
    "\n",
    "#                 if cuda:\n",
    "#                     gene = gene.cuda()\n",
    "#                     noise = noise.cuda()\n",
    "\n",
    "#                 optimizer.zero_grad()\n",
    "#                 output = geneCompressor(gene + noise)\n",
    "#                 loss = criterion(output, gene)\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "#                 total_loss += loss.data\n",
    "\n",
    "#                 if iteration % log_interval == 0 and iteration > 0:\n",
    "#                     cur_loss = total_loss.item() / log_interval\n",
    "#                     elapsed = time.time() - start_time\n",
    "#                     print('| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | loss {:8.5f}'.format(\n",
    "#                         epoch, iteration, int(len(data_loader.dataset) / data_loader.batch_size), elapsed * 1000 / log_interval, cur_loss))\n",
    "#                     total_loss = 0\n",
    "#                     start_time = time.time()\n",
    "\n",
    "#             except KeyError as e:\n",
    "#                 print(f\"Skipping batch due to KeyError: {e}\")\n",
    "#                 continue\n",
    "\n",
    "#     return geneCompressor\n",
    "\n",
    "\n",
    "def geneCompressing(data_loader,num_gene_compressed, noise_weight=0.2, epochs=20, log_interval=10 ):\n",
    "    #model\n",
    "    geneCompressor=GeneCompressor(num_genes, num_out=num_gene_compressed, dropout=0.1)\n",
    "    if cuda: \n",
    "        geneCompressor=geneCompressor.cuda()\n",
    "    criterion=nn.MSELoss()\n",
    "    optimizer=optim.Adam(geneCompressor.parameters())\n",
    "\n",
    "    for epoch in range(1,epochs+1):\n",
    "        #train\n",
    "        geneCompressor.train()\n",
    "        total_loss=0\n",
    "        start_time=time.time()\n",
    "        for iteration, gene in enumerate(data_loader):\n",
    "            gene=Variable(gene).float()\n",
    "            noise=noise_weight*torch.randn(gene.shape)\n",
    "\n",
    "            if cuda:\n",
    "                gene=gene.cuda()\n",
    "                noise=noise.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output=geneCompressor(gene+noise)\n",
    "            loss=criterion(output,gene)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.data\n",
    "            if iteration % log_interval == 0 and iteration > 0:\n",
    "                cur_loss = total_loss.item() / log_interval\n",
    "                elapsed = time.time() - start_time\n",
    "                print('| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | loss {:8.5f}'.format(epoch, iteration, int(len(data_loader)/bsz), elapsed * 1000/log_interval, cur_loss))\n",
    "                total_loss = 0\n",
    "                start_time = time.time()\n",
    "#         #test\n",
    "#         geneCompressor.eval()\n",
    "#         total_loss=0\n",
    "#         start_time=time.time()\n",
    "#         with torch.no_grad():\n",
    "#             for iteration, gene in enumerate(test_data_loader):\n",
    "#                 gene=Variable(gene).float()\n",
    "#                 if cuda:\n",
    "#                     gene=gene.cuda(device)\n",
    "#                 output=geneCompressor(gene)\n",
    "#                 loss=criterion(output,gene)\n",
    "#                 total_loss += loss.data\n",
    "#             print(total_loss.item()/iteration)\n",
    "    return geneCompressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    10/    0 batches | ms/batch 32.90 | loss  0.00778\n",
      "| epoch   1 |    20/    0 batches | ms/batch 16.83 | loss  0.00507\n",
      "| epoch   1 |    30/    0 batches | ms/batch 16.77 | loss  0.00501\n",
      "| epoch   1 |    40/    0 batches | ms/batch 17.85 | loss  0.00505\n",
      "| epoch   1 |    50/    0 batches | ms/batch 16.62 | loss  0.00480\n",
      "| epoch   1 |    60/    0 batches | ms/batch 18.26 | loss  0.00440\n",
      "| epoch   2 |    10/    0 batches | ms/batch 18.01 | loss  0.00423\n",
      "| epoch   2 |    20/    0 batches | ms/batch 15.17 | loss  0.00320\n",
      "| epoch   2 |    30/    0 batches | ms/batch 20.04 | loss  0.00289\n",
      "| epoch   2 |    40/    0 batches | ms/batch 16.97 | loss  0.00245\n",
      "| epoch   2 |    50/    0 batches | ms/batch 16.95 | loss  0.00207\n",
      "| epoch   2 |    60/    0 batches | ms/batch 17.93 | loss  0.00174\n",
      "| epoch   3 |    10/    0 batches | ms/batch 18.01 | loss  0.00150\n",
      "| epoch   3 |    20/    0 batches | ms/batch 17.00 | loss  0.00114\n",
      "| epoch   3 |    30/    0 batches | ms/batch 17.17 | loss  0.00107\n",
      "| epoch   3 |    40/    0 batches | ms/batch 15.81 | loss  0.00089\n",
      "| epoch   3 |    50/    0 batches | ms/batch 17.50 | loss  0.00074\n",
      "| epoch   3 |    60/    0 batches | ms/batch 16.09 | loss  0.00062\n",
      "| epoch   4 |    10/    0 batches | ms/batch 18.37 | loss  0.00065\n",
      "| epoch   4 |    20/    0 batches | ms/batch 16.97 | loss  0.00045\n",
      "| epoch   4 |    30/    0 batches | ms/batch 16.40 | loss  0.00041\n",
      "| epoch   4 |    40/    0 batches | ms/batch 16.83 | loss  0.00037\n",
      "| epoch   4 |    50/    0 batches | ms/batch 16.49 | loss  0.00032\n",
      "| epoch   4 |    60/    0 batches | ms/batch 15.54 | loss  0.00030\n",
      "| epoch   5 |    10/    0 batches | ms/batch 17.30 | loss  0.00029\n",
      "| epoch   5 |    20/    0 batches | ms/batch 17.28 | loss  0.00023\n",
      "| epoch   5 |    30/    0 batches | ms/batch 17.95 | loss  0.00022\n",
      "| epoch   5 |    40/    0 batches | ms/batch 17.58 | loss  0.00021\n",
      "| epoch   5 |    50/    0 batches | ms/batch 17.14 | loss  0.00023\n",
      "| epoch   5 |    60/    0 batches | ms/batch 16.18 | loss  0.00017\n",
      "| epoch   6 |    10/    0 batches | ms/batch 17.67 | loss  0.00018\n",
      "| epoch   6 |    20/    0 batches | ms/batch 17.07 | loss  0.00016\n",
      "| epoch   6 |    30/    0 batches | ms/batch 17.44 | loss  0.00016\n",
      "| epoch   6 |    40/    0 batches | ms/batch 17.88 | loss  0.00020\n",
      "| epoch   6 |    50/    0 batches | ms/batch 16.95 | loss  0.00014\n",
      "| epoch   6 |    60/    0 batches | ms/batch 16.32 | loss  0.00013\n",
      "| epoch   7 |    10/    0 batches | ms/batch 17.32 | loss  0.00015\n",
      "| epoch   7 |    20/    0 batches | ms/batch 15.15 | loss  0.00018\n",
      "| epoch   7 |    30/    0 batches | ms/batch 17.12 | loss  0.00011\n",
      "| epoch   7 |    40/    0 batches | ms/batch 19.17 | loss  0.00012\n",
      "| epoch   7 |    50/    0 batches | ms/batch 17.97 | loss  0.00013\n",
      "| epoch   7 |    60/    0 batches | ms/batch 16.13 | loss  0.00014\n",
      "| epoch   8 |    10/    0 batches | ms/batch 19.15 | loss  0.00012\n",
      "| epoch   8 |    20/    0 batches | ms/batch 17.69 | loss  0.00016\n",
      "| epoch   8 |    30/    0 batches | ms/batch 17.61 | loss  0.00012\n",
      "| epoch   8 |    40/    0 batches | ms/batch 16.53 | loss  0.00014\n",
      "| epoch   8 |    50/    0 batches | ms/batch 18.76 | loss  0.00012\n",
      "| epoch   8 |    60/    0 batches | ms/batch 16.37 | loss  0.00010\n",
      "| epoch   9 |    10/    0 batches | ms/batch 18.32 | loss  0.00012\n",
      "| epoch   9 |    20/    0 batches | ms/batch 17.57 | loss  0.00011\n",
      "| epoch   9 |    30/    0 batches | ms/batch 15.89 | loss  0.00011\n",
      "| epoch   9 |    40/    0 batches | ms/batch 15.61 | loss  0.00010\n",
      "| epoch   9 |    50/    0 batches | ms/batch 17.34 | loss  0.00012\n",
      "| epoch   9 |    60/    0 batches | ms/batch 15.55 | loss  0.00016\n",
      "| epoch  10 |    10/    0 batches | ms/batch 18.19 | loss  0.00014\n",
      "| epoch  10 |    20/    0 batches | ms/batch 15.17 | loss  0.00012\n",
      "| epoch  10 |    30/    0 batches | ms/batch 16.39 | loss  0.00017\n",
      "| epoch  10 |    40/    0 batches | ms/batch 17.02 | loss  0.00011\n",
      "| epoch  10 |    50/    0 batches | ms/batch 16.82 | loss  0.00010\n",
      "| epoch  10 |    60/    0 batches | ms/batch 17.17 | loss  0.00011\n",
      "| epoch  11 |    10/    0 batches | ms/batch 19.07 | loss  0.00014\n",
      "| epoch  11 |    20/    0 batches | ms/batch 16.09 | loss  0.00011\n",
      "| epoch  11 |    30/    0 batches | ms/batch 17.60 | loss  0.00011\n",
      "| epoch  11 |    40/    0 batches | ms/batch 17.38 | loss  0.00016\n",
      "| epoch  11 |    50/    0 batches | ms/batch 17.19 | loss  0.00011\n",
      "| epoch  11 |    60/    0 batches | ms/batch 15.64 | loss  0.00010\n",
      "| epoch  12 |    10/    0 batches | ms/batch 19.48 | loss  0.00012\n",
      "| epoch  12 |    20/    0 batches | ms/batch 16.68 | loss  0.00010\n",
      "| epoch  12 |    30/    0 batches | ms/batch 16.89 | loss  0.00016\n",
      "| epoch  12 |    40/    0 batches | ms/batch 15.69 | loss  0.00010\n",
      "| epoch  12 |    50/    0 batches | ms/batch 15.91 | loss  0.00012\n",
      "| epoch  12 |    60/    0 batches | ms/batch 18.16 | loss  0.00012\n",
      "| epoch  13 |    10/    0 batches | ms/batch 20.05 | loss  0.00013\n",
      "| epoch  13 |    20/    0 batches | ms/batch 19.04 | loss  0.00011\n",
      "| epoch  13 |    30/    0 batches | ms/batch 16.86 | loss  0.00011\n",
      "| epoch  13 |    40/    0 batches | ms/batch 16.83 | loss  0.00010\n",
      "| epoch  13 |    50/    0 batches | ms/batch 16.61 | loss  0.00016\n",
      "| epoch  13 |    60/    0 batches | ms/batch 16.24 | loss  0.00012\n",
      "| epoch  14 |    10/    0 batches | ms/batch 17.73 | loss  0.00012\n",
      "| epoch  14 |    20/    0 batches | ms/batch 16.97 | loss  0.00011\n",
      "| epoch  14 |    30/    0 batches | ms/batch 16.37 | loss  0.00011\n",
      "| epoch  14 |    40/    0 batches | ms/batch 16.14 | loss  0.00015\n",
      "| epoch  14 |    50/    0 batches | ms/batch 17.90 | loss  0.00011\n",
      "| epoch  14 |    60/    0 batches | ms/batch 16.69 | loss  0.00011\n",
      "| epoch  15 |    10/    0 batches | ms/batch 19.30 | loss  0.00011\n",
      "| epoch  15 |    20/    0 batches | ms/batch 16.78 | loss  0.00012\n",
      "| epoch  15 |    30/    0 batches | ms/batch 17.69 | loss  0.00012\n",
      "| epoch  15 |    40/    0 batches | ms/batch 17.99 | loss  0.00010\n",
      "| epoch  15 |    50/    0 batches | ms/batch 17.63 | loss  0.00016\n",
      "| epoch  15 |    60/    0 batches | ms/batch 17.53 | loss  0.00012\n",
      "| epoch  16 |    10/    0 batches | ms/batch 17.48 | loss  0.00014\n",
      "| epoch  16 |    20/    0 batches | ms/batch 15.68 | loss  0.00011\n",
      "| epoch  16 |    30/    0 batches | ms/batch 16.36 | loss  0.00011\n",
      "| epoch  16 |    40/    0 batches | ms/batch 15.54 | loss  0.00011\n",
      "| epoch  16 |    50/    0 batches | ms/batch 16.72 | loss  0.00014\n",
      "| epoch  16 |    60/    0 batches | ms/batch 14.93 | loss  0.00013\n",
      "| epoch  17 |    10/    0 batches | ms/batch 17.83 | loss  0.00017\n",
      "| epoch  17 |    20/    0 batches | ms/batch 19.86 | loss  0.00012\n",
      "| epoch  17 |    30/    0 batches | ms/batch 18.12 | loss  0.00010\n",
      "| epoch  17 |    40/    0 batches | ms/batch 15.45 | loss  0.00011\n",
      "| epoch  17 |    50/    0 batches | ms/batch 16.02 | loss  0.00011\n",
      "| epoch  17 |    60/    0 batches | ms/batch 15.30 | loss  0.00012\n",
      "| epoch  18 |    10/    0 batches | ms/batch 22.60 | loss  0.00012\n",
      "| epoch  18 |    20/    0 batches | ms/batch 15.98 | loss  0.00011\n",
      "| epoch  18 |    30/    0 batches | ms/batch 16.74 | loss  0.00010\n",
      "| epoch  18 |    40/    0 batches | ms/batch 16.81 | loss  0.00017\n",
      "| epoch  18 |    50/    0 batches | ms/batch 16.37 | loss  0.00010\n",
      "| epoch  18 |    60/    0 batches | ms/batch 16.87 | loss  0.00012\n",
      "| epoch  19 |    10/    0 batches | ms/batch 17.62 | loss  0.00013\n",
      "| epoch  19 |    20/    0 batches | ms/batch 15.82 | loss  0.00011\n",
      "| epoch  19 |    30/    0 batches | ms/batch 16.82 | loss  0.00016\n",
      "| epoch  19 |    40/    0 batches | ms/batch 16.07 | loss  0.00011\n",
      "| epoch  19 |    50/    0 batches | ms/batch 17.84 | loss  0.00011\n",
      "| epoch  19 |    60/    0 batches | ms/batch 17.74 | loss  0.00011\n",
      "| epoch  20 |    10/    0 batches | ms/batch 18.86 | loss  0.00013\n",
      "| epoch  20 |    20/    0 batches | ms/batch 16.03 | loss  0.00012\n",
      "| epoch  20 |    30/    0 batches | ms/batch 16.16 | loss  0.00011\n",
      "| epoch  20 |    40/    0 batches | ms/batch 17.41 | loss  0.00011\n",
      "| epoch  20 |    50/    0 batches | ms/batch 16.12 | loss  0.00013\n",
      "| epoch  20 |    60/    0 batches | ms/batch 17.62 | loss  0.00011\n"
     ]
    }
   ],
   "source": [
    "#drug's target gene data\n",
    "drugGeneDataset=DrugTargetDataset(drug_features)\n",
    "drugGeneDataset_loader = DataLoader(drugGeneDataset, batch_size=64, shuffle=True)\n",
    "#learn\n",
    "drugGeneCompressor=geneCompressing(drugGeneDataset_loader, num_gene_compressed_drug)\n",
    "#save\n",
    "drugGeneCompressor.eval()\n",
    "drugGeneCompressed=np.array([drugGeneCompressor.cpu()._encoder(torch.FloatTensor(drugGeneDataset[d])).data.numpy() for d in range(num_drugs)])\n",
    "torch.save(drugGeneCompressor.state_dict(), data_path+'drugGeneCompressor.p')\n",
    "pickle.dump(drugGeneCompressed, open(data_path+'drugGeneCompressed.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugGeneCompressed=pickle.load(open(data_path+'drugGeneCompressed.p', 'rb'))\n",
    "drugGeneCompressed=torch.FloatTensor(drugGeneCompressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     1/    0 batches | ms/batch 158.72 | loss  2.17674\n",
      "| epoch   2 |     1/    0 batches | ms/batch 153.25 | loss  3.03503\n",
      "| epoch   3 |     1/    0 batches | ms/batch 153.40 | loss  2.97886\n",
      "| epoch   4 |     1/    0 batches | ms/batch 152.31 | loss  2.57283\n",
      "| epoch   5 |     1/    0 batches | ms/batch 156.91 | loss  2.21477\n",
      "| epoch   6 |     1/    0 batches | ms/batch 161.93 | loss  2.07943\n",
      "| epoch   7 |     1/    0 batches | ms/batch 162.50 | loss  1.98452\n",
      "| epoch   8 |     1/    0 batches | ms/batch 164.29 | loss  1.91247\n",
      "| epoch   9 |     1/    0 batches | ms/batch 161.50 | loss  1.76785\n",
      "| epoch  10 |     1/    0 batches | ms/batch 158.24 | loss  1.76761\n",
      "| epoch  11 |     1/    0 batches | ms/batch 160.66 | loss  1.63839\n",
      "| epoch  12 |     1/    0 batches | ms/batch 166.66 | loss  1.58713\n",
      "| epoch  13 |     1/    0 batches | ms/batch 161.15 | loss  1.57965\n",
      "| epoch  14 |     1/    0 batches | ms/batch 164.41 | loss  1.53907\n",
      "| epoch  15 |     1/    0 batches | ms/batch 152.95 | loss  1.53255\n",
      "| epoch  16 |     1/    0 batches | ms/batch 153.44 | loss  1.50699\n",
      "| epoch  17 |     1/    0 batches | ms/batch 154.34 | loss  1.49412\n",
      "| epoch  18 |     1/    0 batches | ms/batch 149.99 | loss  1.49499\n",
      "| epoch  19 |     1/    0 batches | ms/batch 152.71 | loss  1.46465\n",
      "| epoch  20 |     1/    0 batches | ms/batch 149.56 | loss  1.44239\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#cell line's gene expression data\n",
    "cellGeneDataset=CellGeneDataset(cell_features)\n",
    "cellGeneDataset_loader = DataLoader(cellGeneDataset, batch_size=64, shuffle=True)\n",
    "#learn\n",
    "cellGeneCompressor=geneCompressing(cellGeneDataset_loader,num_gene_compressed_cell, noise_weight=0.01, log_interval=1 )\n",
    "#save\n",
    "cellGeneCompressor.eval()\n",
    "cellGeneCompressed=np.array([cellGeneCompressor.cpu()._encoder(torch.FloatTensor(cellGeneDataset[d])).data.numpy() for d in range(num_celllines)])\n",
    "torch.save(cellGeneCompressor.state_dict(), data_path+'cellGeneCompressor.p')\n",
    "pickle.dump(cellGeneCompressed, open(data_path+'cellGeneCompressed.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellGeneCompressed=pickle.load(open(data_path+'cellGeneCompressed.p', 'rb'))\n",
    "cellGeneCompressed=torch.FloatTensor(cellGeneCompressed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synergy prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split in cross or external validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_of_interest(tissues):\n",
    "    tissues_of_interests = [codes['tissue'].item2idx[minor_tissue] for minor_tissue in tissues]\n",
    "    cell_of_interest = cell_features.index[cell_features['tissue_id'].isin(tissues_of_interests)].tolist()\n",
    "    return cell_of_interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test for general model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "minor_tissues=['bone', 'prostate' ]\n",
    "cell_of_interest = get_cell_of_interest(minor_tissues)\n",
    "df_tissue_of_interest = df.loc[df['cell_line_name'].isin(cell_of_interest),:]\n",
    "df_all = df.drop(df_tissue_of_interest.index)\n",
    "#specific database\n",
    "#df_all=df_all.loc[df_all['study_id']==3]\n",
    "#cross validation\n",
    "df_train, df_test = train_test_split(df_all, test_size=0.2) #cross validation\n",
    "#external validation\n",
    "#df_train=df_all.loc[df_all['study_id']==3] 3: 'ALMANAC'\n",
    "#df_test=df_all.loc[df_all['study_id']==1] 1: 'ONEIL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test for bone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_bone = df.loc[df['cell_line_name'].isin(get_cell_of_interest(['bone'])),:]\n",
    "# Cross validation\n",
    "_df_train_bone, _df_test_bone = train_test_split(_df_bone, test_size=0.2, random_state=1)\n",
    "# External validation\n",
    "#_df_train_bone=_df_bone.loc[_df_bone['study_id']!=9]\n",
    "#_df_test_bone= _df_bone.loc[_df_bone['study_id']==9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test for prostate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_prostate= df.loc[df['cell_line_name'].isin(get_cell_of_interest(['prostate'])),:]\n",
    "#Cross validation\n",
    "_df_train_prostate, _df_test_prostate = train_test_split(_df_prostate, test_size=0.2, random_state=1)\n",
    "# External validation\n",
    "#_df_train_prostate=_df_prostate.loc[_df_prostate['study_id']!=1]\n",
    "#_df_test_prostate=_df_prostate.loc[_df_prostate['study_id']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugCombDataset(Dataset):\n",
    "    def __init__(self, df, drug_features, cell_features):\n",
    "        self.df = df\n",
    "        self.drug_features = drug_features\n",
    "        self.cell_features = cell_features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        d1 = self.df.iloc[idx, 0]\n",
    "        d2 = self.df.iloc[idx, 1]\n",
    "        cell = self.df.iloc[idx,2]\n",
    "        ri_d1 = 1.0 if self.df.iloc[idx,3] >ri_threshold else 0\n",
    "        ri_d2 = 1.0 if self.df.iloc[idx,4] >ri_threshold else 0\n",
    "        syn = 1.0 if self.df.iloc[idx, 5] >syn_threshold else 0\n",
    "        \n",
    "        \n",
    "        #external features\n",
    "        d1_fp = np.array(self.drug_features.loc[d1, 'fps'])\n",
    "        d1_sm = self.drug_features.loc[d1, 'smiles']\n",
    "        d1_sm = np.pad(d1_sm, pad_width=(0, max_drug_sm_len-len(d1_sm)), mode='constant', constant_values=0)\n",
    "        d1_gn=drugGeneCompressed[d1]\n",
    "        \n",
    "        d2_fp = np.array(self.drug_features.loc[d2, 'fps'])\n",
    "        d2_sm = self.drug_features.loc[d2, 'smiles']\n",
    "        d2_sm = np.pad(d2_sm, pad_width=(0, max_drug_sm_len-len(d2_sm)), mode='constant', constant_values=0)\n",
    "        d2_gn=drugGeneCompressed[d2]\n",
    "        \n",
    "        c_ts = self.cell_features.loc[cell, 'tissue_id']\n",
    "        c_ds = self.cell_features.loc[cell, 'disease_id']\n",
    "        c_gn= cellGeneCompressed[cell]\n",
    "        \n",
    "        sample = {\n",
    "            'd1': d1,\n",
    "            'd1_fp': d1_fp,\n",
    "            'd1_sm': d1_sm,\n",
    "            'd1_gn': d1_gn,\n",
    "            \n",
    "            'd2': d2,\n",
    "            'd2_fp': d2_fp,\n",
    "            'd2_sm': d2_sm,\n",
    "            'd2_gn': d2_gn,\n",
    "            \n",
    "            'cell': cell,\n",
    "            'c_ts': c_ts,\n",
    "            'c_ds': c_ds, #missing -1\n",
    "            'c_gn': c_gn,\n",
    "            \n",
    "            'ri_d1': ri_d1,\n",
    "            'ri_d2': ri_d2,\n",
    "            'syn': syn\n",
    "        }\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DrugCombDataset(df_train, drug_features, cell_features)\n",
    "train_loader = DataLoader(train, batch_size=bsz, shuffle=True )\n",
    "test = DrugCombDataset(df_test, drug_features, cell_features)\n",
    "test_loader = DataLoader(test, batch_size=bsz, shuffle=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_bone = DrugCombDataset(_df_train_bone, drug_features, cell_features)\n",
    "_train_loader_bone = DataLoader(_train_bone, batch_size=bsz, shuffle=True )\n",
    "_test_bone = DrugCombDataset(_df_test_bone, drug_features, cell_features)\n",
    "_test_loader_bone = DataLoader(_test_bone, batch_size=bsz, shuffle=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prostate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_prostate = DrugCombDataset(_df_train_prostate, drug_features, cell_features)\n",
    "_train_loader_prostate = DataLoader(_train_prostate, batch_size=bsz, shuffle=True )\n",
    "_test_prostate = DrugCombDataset(_df_test_prostate, drug_features, cell_features)\n",
    "_test_loader_prostate = DataLoader(_test_prostate, batch_size=bsz, shuffle=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_drugs=num_drugs,\n",
    "                 num_ID_emb=0,\n",
    "                 num_drug_fp=num_drug_fp,\n",
    "                 max_drug_sm_len=max_drug_sm_len,\n",
    "                 num_gene = num_gene_compressed_drug,\n",
    "                 num_comp_char=len(codes['mole'].idx2item),\n",
    "                 fp_embed_sz = 32,\n",
    "                 gene_embed_sz = int(num_gene_compressed_drug/2),\n",
    "                 out_size=64,\n",
    "                 dropout=0.3):\n",
    "        super(DrugEncoder, self).__init__()\n",
    "        \n",
    "        self.dropout= dropout\n",
    "        #DRUG\n",
    "        #drug ID\n",
    "        #self.embed_id = nn.Embedding(num_drugs, num_ID_emb)\n",
    "        \n",
    "        #compound ID\n",
    "        self.embed_comp = nn.Embedding(num_comp_char, num_comp_char, padding_idx=0)#padding's idx=0\n",
    "        #encoding compound\n",
    "        self.encoderlayer = nn.TransformerEncoderLayer(d_model=num_comp_char, nhead=4)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoderlayer, num_layers=1)\n",
    "        \n",
    "        #fingerprint\n",
    "        self.dense_fp = nn.Linear(num_drug_fp,fp_embed_sz)\n",
    "        #gene\n",
    "        self.dense_gene = nn.Linear(num_gene,gene_embed_sz)\n",
    "        \n",
    "        #depthwise for compound encoding\n",
    "        self.conv = nn.Conv2d(1, 1, (1, num_comp_char), groups=1)\n",
    "        \n",
    "        #combined\n",
    "        combined_sz = num_ID_emb+fp_embed_sz+max_drug_sm_len+gene_embed_sz\n",
    "        self.FC2 = FC2(combined_sz, out_size, dropout)\n",
    "\n",
    "    def forward(self, d_list):\n",
    "        \"\"\"\n",
    "            id: bsz*1\n",
    "            fp: bsz*num_drug_fp\n",
    "            sm: bsz*max_drug_sm_len\n",
    "        \"\"\"\n",
    "        id, fp, sm, gn = d_list\n",
    "        \n",
    "        sm = self.embed_comp(sm) #bsz*max_drug_sm_len*num_comp_char(embedding size)\n",
    "        sm = self.encoder(sm)\n",
    "        sm = self.conv(sm.unsqueeze(1)).squeeze()\n",
    "        \n",
    "        fp = F.relu(self.dense_fp(fp))\n",
    "        gn = F.relu(self.dense_gene(gn))\n",
    "        \n",
    "        #combine\n",
    "        x = torch.cat((fp, sm, gn),1) # bsz*[num_emb_id+num_drug_fp+max+drug_sm]\n",
    "        x = self.FC2(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_cells=num_celllines,\n",
    "                 num_tissue=0,\n",
    "                 num_disease=num_disease,\n",
    "                 num_ID_emb=0,\n",
    "                 gene_embed_sz=int(num_gene_compressed_cell/2),\n",
    "                 num_gene=num_gene_compressed_cell,\n",
    "                 out_size=64,\n",
    "                 dropout=0.3):\n",
    "        super(CellEncoder, self).__init__()\n",
    "        \n",
    "        self.dropout= dropout\n",
    "        #cell ID\n",
    "        #self.embed_id = nn.Embedding(num_cells, num_ID_emb)\n",
    "        #cell tissue\n",
    "        #self.embed_ts = nn.Embedding(num_tissue, num_tissue)\n",
    "        #cell disease\n",
    "        self.embed_ds = nn.Embedding(num_disease, num_disease, padding_idx=3)\n",
    "        #gene\n",
    "        self.dense_gene = nn.Linear(num_gene,gene_embed_sz)\n",
    "        \n",
    "        #combined\n",
    "        combined_sz = num_ID_emb+num_tissue+num_disease+gene_embed_sz\n",
    "        self.FC2 = FC2(combined_sz, out_size, dropout)\n",
    "    \n",
    "        \n",
    "    def forward(self, c_list):\n",
    "        \"\"\"\n",
    "            id: bsz*1\n",
    "            fp: bsz*num_drug_fp\n",
    "            sm: bsz*max_drug_sm_len\n",
    "        \"\"\"\n",
    "        id, ts, ds, gn = c_list\n",
    "        ds = F.relu(self.embed_ds(ds)) #bsz*num_diesaes\n",
    "        \n",
    "        gn = F.relu(self.dense_gene(gn)) #bsz*gene_embed_sz\n",
    "        \n",
    "        #combine\n",
    "        x = torch.cat((ds, gn),1) # bsz*combined_sz\n",
    "        x = self.FC2(x)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comb(nn.Module):\n",
    "    def __init__(self, num_cells=num_celllines, \n",
    "                 num_drugs=num_drugs,\n",
    "                 num_drug_fp=num_drug_fp,\n",
    "                 max_drug_sm_len=max_drug_sm_len,\n",
    "                num_comp_char=len(codes['mole'].idx2item),\n",
    "                 num_ID_emb=0,\n",
    "                 out_size=64,\n",
    "                dropout=0.3):\n",
    "        \n",
    "        super(Comb, self).__init__()\n",
    "        \n",
    "        self.dropout=dropout    \n",
    "        #drug\n",
    "        self.drugEncoder = DrugEncoder()\n",
    "        #cell\n",
    "        self.cellEncoder = CellEncoder()\n",
    "        #fc\n",
    "        self.fc_syn = FC2(out_size*3, 1, dropout)\n",
    "        self.fc_ri = FC2(out_size*2, 1, dropout)\n",
    "        \n",
    "    def forward(self, d1_list, d2_list, c_list):\n",
    "        d1 = self.drugEncoder(d1_list)\n",
    "        d2 = self.drugEncoder(d2_list)\n",
    "        c = self.cellEncoder(c_list)\n",
    "        \n",
    "        syn = self.fc_syn(torch.cat((d1, d2, c),1))\n",
    "        ri1 = self.fc_ri(torch.cat((d1,c),1))\n",
    "        ri2 = self.fc_ri(torch.cat((d2,c),1))\n",
    "        \n",
    "        return syn, ri1, ri2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blake/miniconda3/envs/synergy/lib/python3.8/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = Comb()\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "#Regression\n",
    "#criterion_mse = nn.MSELoss()\n",
    "#Classification\n",
    "criterion_bce = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adagrad(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "def training(isAux, data_loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for iteration, sample in enumerate(data_loader):\n",
    "        d1=Variable(sample['d1'])\n",
    "        d1_fp = Variable(sample['d1_fp'].float())\n",
    "        d1_sm = Variable(sample['d1_sm'])\n",
    "        d1_gn = Variable(sample['d1_gn'].float())\n",
    "        \n",
    "        d2=Variable(sample['d2'])\n",
    "        d2_fp = Variable(sample['d2_fp'].float())\n",
    "        d2_sm = Variable(sample['d2_sm'])\n",
    "        d2_gn = Variable(sample['d2_gn'].float())\n",
    "        \n",
    "        cell = Variable(sample['cell'])\n",
    "        c_ts = Variable(sample['c_ts'])\n",
    "        c_ds = Variable(sample['c_ds'])\n",
    "        c_gn = Variable(sample['c_gn'].float())\n",
    "        \n",
    "        syn_true = Variable(sample['syn'].float())\n",
    "        ri_d1=Variable(sample['ri_d1'].float())\n",
    "        ri_d2=Variable(sample['ri_d2'].float())\n",
    "\n",
    "\n",
    "        if cuda:\n",
    "            d1=d1.cuda()\n",
    "            d1_fp=d1_fp.cuda()\n",
    "            d1_sm=d1_sm.cuda()\n",
    "            d1_gn=d1_gn.cuda()\n",
    "            \n",
    "            d2=d2.cuda()\n",
    "            d2_fp=d2_fp.cuda()\n",
    "            d2_sm=d2_sm.cuda()\n",
    "            d2_gn=d2_gn.cuda()\n",
    "            \n",
    "            cell=cell.cuda()\n",
    "            c_ts=c_ts.cuda()\n",
    "            c_ds=c_ds.cuda()\n",
    "            c_gn=c_gn.cuda()\n",
    "            \n",
    "            syn_true=syn_true.cuda()\n",
    "            ri_d1=ri_d1.cuda()\n",
    "            ri_d2=ri_d2.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        syn, ri1, ri2 = model((d1, d1_fp, d1_sm, d1_gn), (d2, d2_fp, d2_sm, d2_gn), (cell, c_ts, c_ds, c_gn) )\n",
    "        \n",
    "        if not isAux:\n",
    "            loss = criterion_bce(syn, syn_true.view(-1,1))\n",
    "        else:\n",
    "            loss = criterion_bce(ri1, ri_d1.view(-1,1))+criterion_bce(ri2, ri_d2.view(-1,1))\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.data\n",
    "\n",
    "        if iteration % log_interval == 0 and iteration > 0:\n",
    "            cur_loss = total_loss.item() / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | loss {:8.5f}'.format(epoch, iteration, int(len(train_loader)/bsz), elapsed * 1000/log_interval, cur_loss))\n",
    "\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_loss_sen = 0\n",
    "\n",
    "    \n",
    "    #loss\n",
    "    with torch.no_grad():\n",
    "        for iteration, sample in enumerate(data_loader):\n",
    "            d1=Variable(sample['d1'])\n",
    "            d1_fp = Variable(sample['d1_fp'].float())\n",
    "            d1_sm = Variable(sample['d1_sm'])\n",
    "            d1_gn = Variable(sample['d1_gn'].float())\n",
    "\n",
    "            d2=Variable(sample['d2'])\n",
    "            d2_fp = Variable(sample['d2_fp'].float())\n",
    "            d2_sm = Variable(sample['d2_sm'])\n",
    "            d2_gn = Variable(sample['d2_gn'].float())\n",
    "\n",
    "            cell = Variable(sample['cell'])\n",
    "            c_ts = Variable(sample['c_ts'])\n",
    "            c_ds = Variable(sample['c_ds'])\n",
    "            c_gn = Variable(sample['c_gn'].float())\n",
    "\n",
    "            syn_true = Variable(sample['syn'].float())\n",
    "            ri_d1=Variable(sample['ri_d1'].float())\n",
    "            ri_d2=Variable(sample['ri_d2'].float())\n",
    "\n",
    "\n",
    "            if cuda:\n",
    "                d1=d1.cuda()\n",
    "                d1_fp=d1_fp.cuda()\n",
    "                d1_sm=d1_sm.cuda()\n",
    "                d1_gn=d1_gn.cuda()\n",
    "\n",
    "                d2=d2.cuda()\n",
    "                d2_fp=d2_fp.cuda()\n",
    "                d2_sm=d2_sm.cuda()\n",
    "                d2_gn=d2_gn.cuda()\n",
    "\n",
    "                cell=cell.cuda()\n",
    "                c_ts=c_ts.cuda()\n",
    "                c_ds=c_ds.cuda()\n",
    "                c_gn=c_gn.cuda()\n",
    "\n",
    "                syn_true=syn_true.cuda()\n",
    "                ri_d1=ri_d1.cuda()\n",
    "                ri_d2=ri_d2.cuda()\n",
    "\n",
    "\n",
    "            syn,ri1,ri2 = model((d1, d1_fp, d1_sm, d1_gn), (d2, d2_fp, d2_sm, d2_gn), (cell, c_ts,c_ds,c_gn) )\n",
    "            loss = criterion_bce(syn, syn_true.view(-1,1))\n",
    "            total_loss +=loss.data\n",
    "            loss_sen = (criterion_bce(ri1, ri_d1.view(-1,1))+criterion_bce(ri2, ri_d2.view(-1,1)))/2\n",
    "            total_loss_sen += loss_sen.data\n",
    "\n",
    "        print('syn mse', total_loss.item()/(iteration+1))\n",
    "        print('sen_mse', total_loss_sen.item()/(iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   100/   18 batches | ms/batch 64.03 | loss  0.37985\n",
      "| epoch   1 |   200/   18 batches | ms/batch 60.23 | loss  0.32795\n",
      "| epoch   1 |   300/   18 batches | ms/batch 59.59 | loss  0.30394\n",
      "| epoch   1 |   400/   18 batches | ms/batch 60.43 | loss  0.29835\n",
      "| epoch   1 |   500/   18 batches | ms/batch 59.54 | loss  0.29231\n",
      "| epoch   1 |   600/   18 batches | ms/batch 60.85 | loss  0.28773\n",
      "| epoch   1 |   700/   18 batches | ms/batch 59.66 | loss  0.29126\n",
      "| epoch   1 |   800/   18 batches | ms/batch 61.18 | loss  0.27300\n",
      "| epoch   1 |   900/   18 batches | ms/batch 60.07 | loss  0.27739\n",
      "| epoch   1 |  1000/   18 batches | ms/batch 60.22 | loss  0.26793\n",
      "| epoch   1 |  1100/   18 batches | ms/batch 61.83 | loss  0.27291\n",
      "| epoch   1 |  1200/   18 batches | ms/batch 60.25 | loss  0.27563\n",
      "| epoch   1 |  1300/   18 batches | ms/batch 60.42 | loss  0.27264\n",
      "| epoch   1 |  1400/   18 batches | ms/batch 62.63 | loss  0.25508\n",
      "| epoch   1 |  1500/   18 batches | ms/batch 60.54 | loss  0.25885\n",
      "| epoch   1 |  1600/   18 batches | ms/batch 60.60 | loss  0.25200\n",
      "| epoch   1 |  1700/   18 batches | ms/batch 60.98 | loss  0.26054\n",
      "| epoch   1 |  1800/   18 batches | ms/batch 63.47 | loss  0.25267\n",
      "| epoch   1 |  1900/   18 batches | ms/batch 60.92 | loss  0.24828\n",
      "| epoch   1 |  2000/   18 batches | ms/batch 61.09 | loss  0.26239\n",
      "| epoch   1 |  2100/   18 batches | ms/batch 61.40 | loss  0.25935\n",
      "| epoch   1 |  2200/   18 batches | ms/batch 62.11 | loss  0.24545\n",
      "| epoch   1 |  2300/   18 batches | ms/batch 62.25 | loss  0.24337\n",
      "| epoch   1 |   100/   18 batches | ms/batch 63.07 | loss  0.26325\n",
      "| epoch   1 |   200/   18 batches | ms/batch 62.39 | loss  0.20507\n",
      "| epoch   1 |   300/   18 batches | ms/batch 62.39 | loss  0.19834\n",
      "| epoch   1 |   400/   18 batches | ms/batch 62.60 | loss  0.20577\n",
      "| epoch   1 |   500/   18 batches | ms/batch 62.73 | loss  0.19887\n",
      "| epoch   1 |   600/   18 batches | ms/batch 66.46 | loss  0.20131\n",
      "| epoch   1 |   700/   18 batches | ms/batch 63.44 | loss  0.20473\n",
      "| epoch   1 |   800/   18 batches | ms/batch 63.40 | loss  0.18676\n",
      "| epoch   1 |   900/   18 batches | ms/batch 63.45 | loss  0.20212\n",
      "| epoch   1 |  1000/   18 batches | ms/batch 63.68 | loss  0.18112\n",
      "| epoch   1 |  1100/   18 batches | ms/batch 63.65 | loss  0.18283\n",
      "| epoch   1 |  1200/   18 batches | ms/batch 63.92 | loss  0.19045\n",
      "| epoch   1 |  1300/   18 batches | ms/batch 63.20 | loss  0.18711\n",
      "| epoch   1 |  1400/   18 batches | ms/batch 67.82 | loss  0.17895\n",
      "| epoch   1 |  1500/   18 batches | ms/batch 64.20 | loss  0.18690\n",
      "| epoch   1 |  1600/   18 batches | ms/batch 64.04 | loss  0.18703\n",
      "| epoch   1 |  1700/   18 batches | ms/batch 63.96 | loss  0.18843\n",
      "| epoch   1 |  1800/   18 batches | ms/batch 63.41 | loss  0.18319\n",
      "| epoch   1 |  1900/   18 batches | ms/batch 63.25 | loss  0.18797\n",
      "| epoch   1 |  2000/   18 batches | ms/batch 63.21 | loss  0.19142\n",
      "| epoch   1 |  2100/   18 batches | ms/batch 63.02 | loss  0.19119\n",
      "| epoch   1 |  2200/   18 batches | ms/batch 63.23 | loss  0.17936\n",
      "| epoch   1 |  2300/   18 batches | ms/batch 68.95 | loss  0.18480\n",
      "syn mse 0.2543105949570246\n",
      "sen_mse 0.08743115151474957\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   100/   18 batches | ms/batch 64.06 | loss  0.26268\n",
      "| epoch   2 |   200/   18 batches | ms/batch 63.87 | loss  0.25181\n",
      "| epoch   2 |   300/   18 batches | ms/batch 62.94 | loss  0.25000\n",
      "| epoch   2 |   400/   18 batches | ms/batch 62.81 | loss  0.24464\n",
      "| epoch   2 |   500/   18 batches | ms/batch 69.16 | loss  0.24092\n",
      "| epoch   2 |   600/   18 batches | ms/batch 63.94 | loss  0.24433\n",
      "| epoch   2 |   700/   18 batches | ms/batch 63.74 | loss  0.23947\n",
      "| epoch   2 |   800/   18 batches | ms/batch 63.80 | loss  0.23806\n",
      "| epoch   2 |   900/   18 batches | ms/batch 63.84 | loss  0.23971\n",
      "| epoch   2 |  1000/   18 batches | ms/batch 63.99 | loss  0.24468\n",
      "| epoch   2 |  1100/   18 batches | ms/batch 63.94 | loss  0.23995\n",
      "| epoch   2 |  1200/   18 batches | ms/batch 64.03 | loss  0.23903\n",
      "| epoch   2 |  1300/   18 batches | ms/batch 64.11 | loss  0.24506\n",
      "| epoch   2 |  1400/   18 batches | ms/batch 64.04 | loss  0.23786\n",
      "| epoch   2 |  1500/   18 batches | ms/batch 64.15 | loss  0.24762\n",
      "| epoch   2 |  1600/   18 batches | ms/batch 64.21 | loss  0.24794\n",
      "| epoch   2 |  1700/   18 batches | ms/batch 64.27 | loss  0.24056\n",
      "| epoch   2 |  1800/   18 batches | ms/batch 64.31 | loss  0.23004\n",
      "| epoch   2 |  1900/   18 batches | ms/batch 71.18 | loss  0.24361\n",
      "| epoch   2 |  2000/   18 batches | ms/batch 64.29 | loss  0.24401\n",
      "| epoch   2 |  2100/   18 batches | ms/batch 64.41 | loss  0.23235\n",
      "| epoch   2 |  2200/   18 batches | ms/batch 64.33 | loss  0.24065\n",
      "| epoch   2 |  2300/   18 batches | ms/batch 64.49 | loss  0.24162\n",
      "| epoch   2 |   100/   18 batches | ms/batch 65.60 | loss  0.19477\n",
      "| epoch   2 |   200/   18 batches | ms/batch 65.49 | loss  0.19229\n",
      "| epoch   2 |   300/   18 batches | ms/batch 65.51 | loss  0.19082\n",
      "| epoch   2 |   400/   18 batches | ms/batch 66.22 | loss  0.18474\n",
      "| epoch   2 |   500/   18 batches | ms/batch 65.08 | loss  0.18272\n",
      "| epoch   2 |   600/   18 batches | ms/batch 63.86 | loss  0.18362\n",
      "| epoch   2 |   700/   18 batches | ms/batch 63.86 | loss  0.19018\n",
      "| epoch   2 |   800/   18 batches | ms/batch 64.67 | loss  0.19160\n",
      "| epoch   2 |   900/   18 batches | ms/batch 64.98 | loss  0.18213\n",
      "| epoch   2 |  1000/   18 batches | ms/batch 64.92 | loss  0.18426\n",
      "| epoch   2 |  1100/   18 batches | ms/batch 65.22 | loss  0.18598\n",
      "| epoch   2 |  1200/   18 batches | ms/batch 64.51 | loss  0.18473\n",
      "| epoch   2 |  1300/   18 batches | ms/batch 72.94 | loss  0.17829\n",
      "| epoch   2 |  1400/   18 batches | ms/batch 64.59 | loss  0.18084\n",
      "| epoch   2 |  1500/   18 batches | ms/batch 64.69 | loss  0.18744\n",
      "| epoch   2 |  1600/   18 batches | ms/batch 64.30 | loss  0.17849\n",
      "| epoch   2 |  1700/   18 batches | ms/batch 64.74 | loss  0.18678\n",
      "| epoch   2 |  1800/   18 batches | ms/batch 64.81 | loss  0.19649\n",
      "| epoch   2 |  1900/   18 batches | ms/batch 64.80 | loss  0.17762\n",
      "| epoch   2 |  2000/   18 batches | ms/batch 64.79 | loss  0.18749\n",
      "| epoch   2 |  2100/   18 batches | ms/batch 64.61 | loss  0.18811\n",
      "| epoch   2 |  2200/   18 batches | ms/batch 64.44 | loss  0.18588\n",
      "| epoch   2 |  2300/   18 batches | ms/batch 64.55 | loss  0.18068\n",
      "syn mse 0.22151344700863487\n",
      "sen_mse 0.08616036510629443\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   100/   18 batches | ms/batch 64.26 | loss  0.25098\n",
      "| epoch   3 |   200/   18 batches | ms/batch 63.76 | loss  0.23367\n",
      "| epoch   3 |   300/   18 batches | ms/batch 63.94 | loss  0.24271\n",
      "| epoch   3 |   400/   18 batches | ms/batch 63.99 | loss  0.22830\n",
      "| epoch   3 |   500/   18 batches | ms/batch 74.02 | loss  0.22868\n",
      "| epoch   3 |   600/   18 batches | ms/batch 63.97 | loss  0.23881\n",
      "| epoch   3 |   700/   18 batches | ms/batch 64.42 | loss  0.23572\n",
      "| epoch   3 |   800/   18 batches | ms/batch 64.83 | loss  0.23292\n",
      "| epoch   3 |   900/   18 batches | ms/batch 64.95 | loss  0.24006\n",
      "| epoch   3 |  1000/   18 batches | ms/batch 64.90 | loss  0.23410\n",
      "| epoch   3 |  1100/   18 batches | ms/batch 64.84 | loss  0.23734\n",
      "| epoch   3 |  1200/   18 batches | ms/batch 64.81 | loss  0.22822\n",
      "| epoch   3 |  1300/   18 batches | ms/batch 65.00 | loss  0.23077\n",
      "| epoch   3 |  1400/   18 batches | ms/batch 64.95 | loss  0.23237\n",
      "| epoch   3 |  1500/   18 batches | ms/batch 64.93 | loss  0.22709\n",
      "| epoch   3 |  1600/   18 batches | ms/batch 64.88 | loss  0.22527\n",
      "| epoch   3 |  1700/   18 batches | ms/batch 65.01 | loss  0.22821\n",
      "| epoch   3 |  1800/   18 batches | ms/batch 64.98 | loss  0.23412\n",
      "| epoch   3 |  1900/   18 batches | ms/batch 64.97 | loss  0.22986\n",
      "| epoch   3 |  2000/   18 batches | ms/batch 64.91 | loss  0.22457\n",
      "| epoch   3 |  2100/   18 batches | ms/batch 65.03 | loss  0.23178\n",
      "| epoch   3 |  2200/   18 batches | ms/batch 65.08 | loss  0.22835\n",
      "| epoch   3 |  2300/   18 batches | ms/batch 65.02 | loss  0.22208\n",
      "| epoch   3 |   100/   18 batches | ms/batch 65.86 | loss  0.19038\n",
      "| epoch   3 |   200/   18 batches | ms/batch 65.32 | loss  0.18335\n",
      "| epoch   3 |   300/   18 batches | ms/batch 65.40 | loss  0.18314\n",
      "| epoch   3 |   400/   18 batches | ms/batch 65.42 | loss  0.18453\n",
      "| epoch   3 |   500/   18 batches | ms/batch 65.41 | loss  0.18256\n",
      "| epoch   3 |   600/   18 batches | ms/batch 65.43 | loss  0.18527\n",
      "| epoch   3 |   700/   18 batches | ms/batch 65.34 | loss  0.18243\n",
      "| epoch   3 |   800/   18 batches | ms/batch 77.63 | loss  0.18251\n",
      "| epoch   3 |   900/   18 batches | ms/batch 65.34 | loss  0.18651\n",
      "| epoch   3 |  1000/   18 batches | ms/batch 64.79 | loss  0.18008\n",
      "| epoch   3 |  1100/   18 batches | ms/batch 65.52 | loss  0.18087\n",
      "| epoch   3 |  1200/   18 batches | ms/batch 64.61 | loss  0.18416\n",
      "| epoch   3 |  1300/   18 batches | ms/batch 64.68 | loss  0.18037\n",
      "| epoch   3 |  1400/   18 batches | ms/batch 64.65 | loss  0.17527\n",
      "| epoch   3 |  1500/   18 batches | ms/batch 64.67 | loss  0.17842\n",
      "| epoch   3 |  1600/   18 batches | ms/batch 64.82 | loss  0.17631\n",
      "| epoch   3 |  1700/   18 batches | ms/batch 64.93 | loss  0.17736\n",
      "| epoch   3 |  1800/   18 batches | ms/batch 65.25 | loss  0.17560\n",
      "| epoch   3 |  1900/   18 batches | ms/batch 65.49 | loss  0.18304\n",
      "| epoch   3 |  2000/   18 batches | ms/batch 64.66 | loss  0.17938\n",
      "| epoch   3 |  2100/   18 batches | ms/batch 64.57 | loss  0.18198\n",
      "| epoch   3 |  2200/   18 batches | ms/batch 64.40 | loss  0.18383\n",
      "| epoch   3 |  2300/   18 batches | ms/batch 65.46 | loss  0.18453\n",
      "syn mse 0.21677542461401741\n",
      "sen_mse 0.08573236773090978\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |   100/   18 batches | ms/batch 64.36 | loss  0.23648\n",
      "| epoch   4 |   200/   18 batches | ms/batch 64.03 | loss  0.23320\n",
      "| epoch   4 |   300/   18 batches | ms/batch 64.12 | loss  0.22518\n",
      "| epoch   4 |   400/   18 batches | ms/batch 64.36 | loss  0.23071\n",
      "| epoch   4 |   500/   18 batches | ms/batch 65.18 | loss  0.22949\n",
      "| epoch   4 |   600/   18 batches | ms/batch 65.34 | loss  0.23152\n",
      "| epoch   4 |   700/   18 batches | ms/batch 65.43 | loss  0.22249\n",
      "| epoch   4 |   800/   18 batches | ms/batch 65.47 | loss  0.22986\n",
      "| epoch   4 |   900/   18 batches | ms/batch 65.10 | loss  0.22264\n",
      "| epoch   4 |  1000/   18 batches | ms/batch 79.40 | loss  0.22754\n",
      "| epoch   4 |  1100/   18 batches | ms/batch 64.60 | loss  0.23182\n",
      "| epoch   4 |  1200/   18 batches | ms/batch 64.43 | loss  0.21922\n",
      "| epoch   4 |  1300/   18 batches | ms/batch 64.55 | loss  0.22220\n",
      "| epoch   4 |  1400/   18 batches | ms/batch 65.01 | loss  0.22535\n",
      "| epoch   4 |  1500/   18 batches | ms/batch 64.98 | loss  0.22652\n",
      "| epoch   4 |  1600/   18 batches | ms/batch 64.48 | loss  0.23106\n",
      "| epoch   4 |  1700/   18 batches | ms/batch 64.39 | loss  0.22670\n",
      "| epoch   4 |  1800/   18 batches | ms/batch 64.48 | loss  0.22721\n",
      "| epoch   4 |  1900/   18 batches | ms/batch 64.44 | loss  0.22303\n",
      "| epoch   4 |  2000/   18 batches | ms/batch 64.50 | loss  0.21795\n",
      "| epoch   4 |  2100/   18 batches | ms/batch 66.32 | loss  0.22403\n",
      "| epoch   4 |  2200/   18 batches | ms/batch 65.68 | loss  0.22239\n",
      "| epoch   4 |  2300/   18 batches | ms/batch 64.93 | loss  0.22044\n",
      "| epoch   4 |   100/   18 batches | ms/batch 65.79 | loss  0.17896\n",
      "| epoch   4 |   200/   18 batches | ms/batch 65.10 | loss  0.18324\n",
      "| epoch   4 |   300/   18 batches | ms/batch 65.58 | loss  0.18479\n",
      "| epoch   4 |   400/   18 batches | ms/batch 65.35 | loss  0.18613\n",
      "| epoch   4 |   500/   18 batches | ms/batch 65.20 | loss  0.16816\n",
      "| epoch   4 |   600/   18 batches | ms/batch 65.24 | loss  0.17978\n",
      "| epoch   4 |   700/   18 batches | ms/batch 65.19 | loss  0.18007\n",
      "| epoch   4 |   800/   18 batches | ms/batch 65.11 | loss  0.17182\n",
      "| epoch   4 |   900/   18 batches | ms/batch 64.97 | loss  0.19127\n",
      "| epoch   4 |  1000/   18 batches | ms/batch 65.63 | loss  0.17657\n",
      "| epoch   4 |  1100/   18 batches | ms/batch 65.80 | loss  0.17876\n",
      "| epoch   4 |  1200/   18 batches | ms/batch 65.55 | loss  0.17440\n",
      "| epoch   4 |  1300/   18 batches | ms/batch 65.21 | loss  0.16377\n",
      "| epoch   4 |  1400/   18 batches | ms/batch 64.92 | loss  0.17120\n",
      "| epoch   4 |  1500/   18 batches | ms/batch 65.11 | loss  0.18191\n",
      "| epoch   4 |  1600/   18 batches | ms/batch 65.17 | loss  0.17497\n",
      "| epoch   4 |  1700/   18 batches | ms/batch 64.95 | loss  0.17957\n",
      "| epoch   4 |  1800/   18 batches | ms/batch 65.39 | loss  0.17119\n",
      "| epoch   4 |  1900/   18 batches | ms/batch 65.30 | loss  0.17838\n",
      "| epoch   4 |  2000/   18 batches | ms/batch 65.70 | loss  0.16974\n",
      "| epoch   4 |  2100/   18 batches | ms/batch 65.45 | loss  0.17298\n",
      "| epoch   4 |  2200/   18 batches | ms/batch 65.44 | loss  0.17914\n",
      "| epoch   4 |  2300/   18 batches | ms/batch 65.49 | loss  0.18105\n",
      "syn mse 0.2069829736784075\n",
      "sen_mse 0.08505739947126353\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |   100/   18 batches | ms/batch 64.56 | loss  0.23400\n",
      "| epoch   5 |   200/   18 batches | ms/batch 64.51 | loss  0.22360\n",
      "| epoch   5 |   300/   18 batches | ms/batch 64.82 | loss  0.22357\n",
      "| epoch   5 |   400/   18 batches | ms/batch 64.99 | loss  0.21958\n",
      "| epoch   5 |   500/   18 batches | ms/batch 65.61 | loss  0.21320\n",
      "| epoch   5 |   600/   18 batches | ms/batch 65.06 | loss  0.22028\n",
      "| epoch   5 |   700/   18 batches | ms/batch 65.16 | loss  0.22386\n",
      "| epoch   5 |   800/   18 batches | ms/batch 65.27 | loss  0.22609\n",
      "| epoch   5 |   900/   18 batches | ms/batch 65.62 | loss  0.21943\n",
      "| epoch   5 |  1000/   18 batches | ms/batch 65.90 | loss  0.22098\n",
      "| epoch   5 |  1100/   18 batches | ms/batch 66.09 | loss  0.22545\n",
      "| epoch   5 |  1200/   18 batches | ms/batch 65.63 | loss  0.21187\n",
      "| epoch   5 |  1300/   18 batches | ms/batch 65.84 | loss  0.22050\n",
      "| epoch   5 |  1400/   18 batches | ms/batch 66.29 | loss  0.22424\n",
      "| epoch   5 |  1500/   18 batches | ms/batch 66.16 | loss  0.22828\n",
      "| epoch   5 |  1600/   18 batches | ms/batch 65.55 | loss  0.22432\n",
      "| epoch   5 |  1700/   18 batches | ms/batch 65.11 | loss  0.21879\n",
      "| epoch   5 |  1800/   18 batches | ms/batch 65.21 | loss  0.21826\n",
      "| epoch   5 |  1900/   18 batches | ms/batch 65.29 | loss  0.21194\n",
      "| epoch   5 |  2000/   18 batches | ms/batch 65.07 | loss  0.21515\n",
      "| epoch   5 |  2100/   18 batches | ms/batch 64.99 | loss  0.21136\n",
      "| epoch   5 |  2200/   18 batches | ms/batch 64.81 | loss  0.21732\n",
      "| epoch   5 |  2300/   18 batches | ms/batch 64.76 | loss  0.22233\n",
      "| epoch   5 |   100/   18 batches | ms/batch 66.10 | loss  0.18260\n",
      "| epoch   5 |   200/   18 batches | ms/batch 65.16 | loss  0.17568\n",
      "| epoch   5 |   300/   18 batches | ms/batch 64.73 | loss  0.17924\n",
      "| epoch   5 |   400/   18 batches | ms/batch 64.70 | loss  0.17674\n",
      "| epoch   5 |   500/   18 batches | ms/batch 64.93 | loss  0.18564\n",
      "| epoch   5 |   600/   18 batches | ms/batch 65.15 | loss  0.17513\n",
      "| epoch   5 |   700/   18 batches | ms/batch 65.11 | loss  0.17742\n",
      "| epoch   5 |   800/   18 batches | ms/batch 65.20 | loss  0.16628\n",
      "| epoch   5 |   900/   18 batches | ms/batch 65.27 | loss  0.18088\n",
      "| epoch   5 |  1000/   18 batches | ms/batch 65.18 | loss  0.17178\n",
      "| epoch   5 |  1100/   18 batches | ms/batch 65.07 | loss  0.17098\n",
      "| epoch   5 |  1200/   18 batches | ms/batch 65.04 | loss  0.17969\n",
      "| epoch   5 |  1300/   18 batches | ms/batch 65.14 | loss  0.16816\n",
      "| epoch   5 |  1400/   18 batches | ms/batch 65.16 | loss  0.17911\n",
      "| epoch   5 |  1500/   18 batches | ms/batch 64.95 | loss  0.17167\n",
      "| epoch   5 |  1600/   18 batches | ms/batch 64.97 | loss  0.16563\n",
      "| epoch   5 |  1700/   18 batches | ms/batch 64.54 | loss  0.17235\n",
      "| epoch   5 |  1800/   18 batches | ms/batch 64.03 | loss  0.17439\n",
      "| epoch   5 |  1900/   18 batches | ms/batch 86.47 | loss  0.17294\n",
      "| epoch   5 |  2000/   18 batches | ms/batch 63.92 | loss  0.17490\n",
      "| epoch   5 |  2100/   18 batches | ms/batch 64.12 | loss  0.17487\n",
      "| epoch   5 |  2200/   18 batches | ms/batch 64.92 | loss  0.17114\n",
      "| epoch   5 |  2300/   18 batches | ms/batch 64.48 | loss  0.16404\n",
      "syn mse 0.19846873777224375\n",
      "sen_mse 0.08516834952025745\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |   100/   18 batches | ms/batch 64.06 | loss  0.22909\n",
      "| epoch   6 |   200/   18 batches | ms/batch 64.19 | loss  0.22193\n",
      "| epoch   6 |   300/   18 batches | ms/batch 64.18 | loss  0.22335\n",
      "| epoch   6 |   400/   18 batches | ms/batch 64.57 | loss  0.21875\n",
      "| epoch   6 |   500/   18 batches | ms/batch 64.81 | loss  0.22503\n",
      "| epoch   6 |   600/   18 batches | ms/batch 64.95 | loss  0.21889\n",
      "| epoch   6 |   700/   18 batches | ms/batch 64.99 | loss  0.21511\n",
      "| epoch   6 |   800/   18 batches | ms/batch 64.99 | loss  0.22111\n",
      "| epoch   6 |   900/   18 batches | ms/batch 65.13 | loss  0.22216\n",
      "| epoch   6 |  1000/   18 batches | ms/batch 65.14 | loss  0.21305\n",
      "| epoch   6 |  1100/   18 batches | ms/batch 65.15 | loss  0.21321\n",
      "| epoch   6 |  1200/   18 batches | ms/batch 65.41 | loss  0.22365\n",
      "| epoch   6 |  1300/   18 batches | ms/batch 65.46 | loss  0.20861\n",
      "| epoch   6 |  1400/   18 batches | ms/batch 65.53 | loss  0.20979\n",
      "| epoch   6 |  1500/   18 batches | ms/batch 65.44 | loss  0.21483\n",
      "| epoch   6 |  1600/   18 batches | ms/batch 65.53 | loss  0.21315\n",
      "| epoch   6 |  1700/   18 batches | ms/batch 65.11 | loss  0.21323\n",
      "| epoch   6 |  1800/   18 batches | ms/batch 64.93 | loss  0.21180\n",
      "| epoch   6 |  1900/   18 batches | ms/batch 65.29 | loss  0.21645\n",
      "| epoch   6 |  2000/   18 batches | ms/batch 65.40 | loss  0.21117\n",
      "| epoch   6 |  2100/   18 batches | ms/batch 64.80 | loss  0.20643\n",
      "| epoch   6 |  2200/   18 batches | ms/batch 64.91 | loss  0.20771\n",
      "| epoch   6 |  2300/   18 batches | ms/batch 64.91 | loss  0.21071\n",
      "| epoch   6 |   100/   18 batches | ms/batch 65.78 | loss  0.17400\n",
      "| epoch   6 |   200/   18 batches | ms/batch 64.96 | loss  0.18518\n",
      "| epoch   6 |   300/   18 batches | ms/batch 64.88 | loss  0.16763\n",
      "| epoch   6 |   400/   18 batches | ms/batch 65.71 | loss  0.17156\n",
      "| epoch   6 |   500/   18 batches | ms/batch 65.25 | loss  0.17603\n",
      "| epoch   6 |   600/   18 batches | ms/batch 64.97 | loss  0.17879\n",
      "| epoch   6 |   700/   18 batches | ms/batch 65.12 | loss  0.17870\n",
      "| epoch   6 |   800/   18 batches | ms/batch 65.20 | loss  0.16844\n",
      "| epoch   6 |   900/   18 batches | ms/batch 65.17 | loss  0.17381\n",
      "| epoch   6 |  1000/   18 batches | ms/batch 65.87 | loss  0.17793\n",
      "| epoch   6 |  1100/   18 batches | ms/batch 65.45 | loss  0.17213\n",
      "| epoch   6 |  1200/   18 batches | ms/batch 65.08 | loss  0.16171\n",
      "| epoch   6 |  1300/   18 batches | ms/batch 65.23 | loss  0.17211\n",
      "| epoch   6 |  1400/   18 batches | ms/batch 65.14 | loss  0.16826\n",
      "| epoch   6 |  1500/   18 batches | ms/batch 65.15 | loss  0.17093\n",
      "| epoch   6 |  1600/   18 batches | ms/batch 65.16 | loss  0.16948\n",
      "| epoch   6 |  1700/   18 batches | ms/batch 65.06 | loss  0.16953\n",
      "| epoch   6 |  1800/   18 batches | ms/batch 65.46 | loss  0.17631\n",
      "| epoch   6 |  1900/   18 batches | ms/batch 65.75 | loss  0.17081\n",
      "| epoch   6 |  2000/   18 batches | ms/batch 65.72 | loss  0.16093\n",
      "| epoch   6 |  2100/   18 batches | ms/batch 65.67 | loss  0.16651\n",
      "| epoch   6 |  2200/   18 batches | ms/batch 65.71 | loss  0.16398\n",
      "| epoch   6 |  2300/   18 batches | ms/batch 92.79 | loss  0.16759\n",
      "syn mse 0.19080648114604334\n",
      "sen_mse 0.0845786193433156\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |   100/   18 batches | ms/batch 65.30 | loss  0.22736\n",
      "| epoch   7 |   200/   18 batches | ms/batch 64.91 | loss  0.21873\n",
      "| epoch   7 |   300/   18 batches | ms/batch 65.07 | loss  0.21608\n",
      "| epoch   7 |   400/   18 batches | ms/batch 64.71 | loss  0.20393\n",
      "| epoch   7 |   500/   18 batches | ms/batch 64.64 | loss  0.20909\n",
      "| epoch   7 |   600/   18 batches | ms/batch 64.70 | loss  0.21614\n",
      "| epoch   7 |   700/   18 batches | ms/batch 64.29 | loss  0.21685\n",
      "| epoch   7 |   800/   18 batches | ms/batch 64.41 | loss  0.21513\n",
      "| epoch   7 |   900/   18 batches | ms/batch 64.48 | loss  0.21313\n",
      "| epoch   7 |  1000/   18 batches | ms/batch 64.84 | loss  0.20775\n",
      "| epoch   7 |  1100/   18 batches | ms/batch 64.78 | loss  0.20238\n",
      "| epoch   7 |  1200/   18 batches | ms/batch 64.74 | loss  0.21052\n",
      "| epoch   7 |  1300/   18 batches | ms/batch 65.00 | loss  0.21419\n",
      "| epoch   7 |  1400/   18 batches | ms/batch 65.25 | loss  0.20932\n",
      "| epoch   7 |  1500/   18 batches | ms/batch 64.93 | loss  0.20585\n",
      "| epoch   7 |  1600/   18 batches | ms/batch 64.80 | loss  0.21487\n",
      "| epoch   7 |  1700/   18 batches | ms/batch 64.62 | loss  0.21220\n",
      "| epoch   7 |  1800/   18 batches | ms/batch 65.20 | loss  0.21108\n",
      "| epoch   7 |  1900/   18 batches | ms/batch 65.09 | loss  0.20836\n",
      "| epoch   7 |  2000/   18 batches | ms/batch 65.17 | loss  0.20794\n",
      "| epoch   7 |  2100/   18 batches | ms/batch 65.10 | loss  0.20685\n",
      "| epoch   7 |  2200/   18 batches | ms/batch 65.16 | loss  0.20377\n",
      "| epoch   7 |  2300/   18 batches | ms/batch 65.66 | loss  0.19959\n",
      "| epoch   7 |   100/   18 batches | ms/batch 66.47 | loss  0.17625\n",
      "| epoch   7 |   200/   18 batches | ms/batch 65.77 | loss  0.17943\n",
      "| epoch   7 |   300/   18 batches | ms/batch 65.73 | loss  0.16363\n",
      "| epoch   7 |   400/   18 batches | ms/batch 65.81 | loss  0.17222\n",
      "| epoch   7 |   500/   18 batches | ms/batch 65.63 | loss  0.16729\n",
      "| epoch   7 |   600/   18 batches | ms/batch 65.58 | loss  0.17401\n",
      "| epoch   7 |   700/   18 batches | ms/batch 64.94 | loss  0.16242\n",
      "| epoch   7 |   800/   18 batches | ms/batch 64.44 | loss  0.16080\n",
      "| epoch   7 |   900/   18 batches | ms/batch 64.47 | loss  0.17713\n",
      "| epoch   7 |  1000/   18 batches | ms/batch 64.97 | loss  0.16676\n",
      "| epoch   7 |  1100/   18 batches | ms/batch 64.62 | loss  0.16551\n",
      "| epoch   7 |  1200/   18 batches | ms/batch 64.37 | loss  0.16918\n",
      "| epoch   7 |  1300/   18 batches | ms/batch 64.40 | loss  0.17585\n",
      "| epoch   7 |  1400/   18 batches | ms/batch 64.40 | loss  0.16201\n",
      "| epoch   7 |  1500/   18 batches | ms/batch 64.44 | loss  0.16905\n",
      "| epoch   7 |  1600/   18 batches | ms/batch 64.31 | loss  0.16185\n",
      "| epoch   7 |  1700/   18 batches | ms/batch 64.22 | loss  0.16967\n",
      "| epoch   7 |  1800/   18 batches | ms/batch 64.39 | loss  0.16751\n",
      "| epoch   7 |  1900/   18 batches | ms/batch 64.95 | loss  0.16455\n",
      "| epoch   7 |  2000/   18 batches | ms/batch 64.23 | loss  0.16365\n",
      "| epoch   7 |  2100/   18 batches | ms/batch 64.40 | loss  0.16761\n",
      "| epoch   7 |  2200/   18 batches | ms/batch 64.45 | loss  0.17346\n",
      "| epoch   7 |  2300/   18 batches | ms/batch 64.36 | loss  0.17098\n",
      "syn mse 0.18812217777168003\n",
      "sen_mse 0.08522069312518238\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |   100/   18 batches | ms/batch 64.04 | loss  0.22361\n",
      "| epoch   8 |   200/   18 batches | ms/batch 63.76 | loss  0.21477\n",
      "| epoch   8 |   300/   18 batches | ms/batch 63.98 | loss  0.20541\n",
      "| epoch   8 |   400/   18 batches | ms/batch 64.06 | loss  0.21649\n",
      "| epoch   8 |   500/   18 batches | ms/batch 64.12 | loss  0.20100\n",
      "| epoch   8 |   600/   18 batches | ms/batch 64.58 | loss  0.20693\n",
      "| epoch   8 |   700/   18 batches | ms/batch 64.91 | loss  0.21520\n",
      "| epoch   8 |   800/   18 batches | ms/batch 64.99 | loss  0.19996\n",
      "| epoch   8 |   900/   18 batches | ms/batch 64.88 | loss  0.20392\n",
      "| epoch   8 |  1000/   18 batches | ms/batch 64.99 | loss  0.20566\n",
      "| epoch   8 |  1100/   18 batches | ms/batch 97.55 | loss  0.20679\n",
      "| epoch   8 |  1200/   18 batches | ms/batch 64.57 | loss  0.20510\n",
      "| epoch   8 |  1300/   18 batches | ms/batch 64.60 | loss  0.21073\n",
      "| epoch   8 |  1400/   18 batches | ms/batch 64.76 | loss  0.20847\n",
      "| epoch   8 |  1500/   18 batches | ms/batch 64.92 | loss  0.20819\n",
      "| epoch   8 |  1600/   18 batches | ms/batch 64.95 | loss  0.20752\n",
      "| epoch   8 |  1700/   18 batches | ms/batch 65.05 | loss  0.21598\n",
      "| epoch   8 |  1800/   18 batches | ms/batch 64.73 | loss  0.20092\n",
      "| epoch   8 |  1900/   18 batches | ms/batch 64.55 | loss  0.20871\n",
      "| epoch   8 |  2000/   18 batches | ms/batch 64.98 | loss  0.20643\n",
      "| epoch   8 |  2100/   18 batches | ms/batch 64.53 | loss  0.21003\n",
      "| epoch   8 |  2200/   18 batches | ms/batch 64.58 | loss  0.20457\n",
      "| epoch   8 |  2300/   18 batches | ms/batch 64.70 | loss  0.20371\n",
      "| epoch   8 |   100/   18 batches | ms/batch 65.52 | loss  0.17204\n",
      "| epoch   8 |   200/   18 batches | ms/batch 64.73 | loss  0.16890\n",
      "| epoch   8 |   300/   18 batches | ms/batch 64.86 | loss  0.17482\n",
      "| epoch   8 |   400/   18 batches | ms/batch 65.32 | loss  0.16791\n",
      "| epoch   8 |   500/   18 batches | ms/batch 64.77 | loss  0.17022\n",
      "| epoch   8 |   600/   18 batches | ms/batch 64.63 | loss  0.16262\n",
      "| epoch   8 |   700/   18 batches | ms/batch 64.50 | loss  0.17019\n",
      "| epoch   8 |   800/   18 batches | ms/batch 64.76 | loss  0.16692\n",
      "| epoch   8 |   900/   18 batches | ms/batch 64.90 | loss  0.16621\n",
      "| epoch   8 |  1000/   18 batches | ms/batch 64.86 | loss  0.17538\n",
      "| epoch   8 |  1100/   18 batches | ms/batch 64.94 | loss  0.16171\n",
      "| epoch   8 |  1200/   18 batches | ms/batch 64.88 | loss  0.16988\n",
      "| epoch   8 |  1300/   18 batches | ms/batch 64.86 | loss  0.16153\n",
      "| epoch   8 |  1400/   18 batches | ms/batch 64.94 | loss  0.15804\n",
      "| epoch   8 |  1500/   18 batches | ms/batch 64.86 | loss  0.16528\n",
      "| epoch   8 |  1600/   18 batches | ms/batch 64.78 | loss  0.15437\n",
      "| epoch   8 |  1700/   18 batches | ms/batch 65.01 | loss  0.15795\n",
      "| epoch   8 |  1800/   18 batches | ms/batch 64.94 | loss  0.15622\n",
      "| epoch   8 |  1900/   18 batches | ms/batch 64.91 | loss  0.17293\n",
      "| epoch   8 |  2000/   18 batches | ms/batch 64.90 | loss  0.16260\n",
      "| epoch   8 |  2100/   18 batches | ms/batch 64.51 | loss  0.16480\n",
      "| epoch   8 |  2200/   18 batches | ms/batch 64.15 | loss  0.17624\n",
      "| epoch   8 |  2300/   18 batches | ms/batch 64.27 | loss  0.16595\n",
      "syn mse 0.18658554776617545\n",
      "sen_mse 0.08494996619750769\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |   100/   18 batches | ms/batch 63.94 | loss  0.21736\n",
      "| epoch   9 |   200/   18 batches | ms/batch 63.48 | loss  0.21709\n",
      "| epoch   9 |   300/   18 batches | ms/batch 63.74 | loss  0.21052\n",
      "| epoch   9 |   400/   18 batches | ms/batch 63.85 | loss  0.20220\n",
      "| epoch   9 |   500/   18 batches | ms/batch 63.97 | loss  0.19909\n",
      "| epoch   9 |   600/   18 batches | ms/batch 64.37 | loss  0.20288\n",
      "| epoch   9 |   700/   18 batches | ms/batch 65.06 | loss  0.21145\n",
      "| epoch   9 |   800/   18 batches | ms/batch 64.27 | loss  0.20795\n",
      "| epoch   9 |   900/   18 batches | ms/batch 64.34 | loss  0.20704\n",
      "| epoch   9 |  1000/   18 batches | ms/batch 64.38 | loss  0.19976\n",
      "| epoch   9 |  1100/   18 batches | ms/batch 65.32 | loss  0.20239\n",
      "| epoch   9 |  1200/   18 batches | ms/batch 65.43 | loss  0.20551\n",
      "| epoch   9 |  1300/   18 batches | ms/batch 65.42 | loss  0.20216\n",
      "| epoch   9 |  1400/   18 batches | ms/batch 65.50 | loss  0.20253\n",
      "| epoch   9 |  1500/   18 batches | ms/batch 65.45 | loss  0.20688\n",
      "| epoch   9 |  1600/   18 batches | ms/batch 65.45 | loss  0.19936\n",
      "| epoch   9 |  1700/   18 batches | ms/batch 65.50 | loss  0.20369\n",
      "| epoch   9 |  1800/   18 batches | ms/batch 65.69 | loss  0.20933\n",
      "| epoch   9 |  1900/   18 batches | ms/batch 65.60 | loss  0.19879\n",
      "| epoch   9 |  2000/   18 batches | ms/batch 65.14 | loss  0.20578\n",
      "| epoch   9 |  2100/   18 batches | ms/batch 65.49 | loss  0.20263\n",
      "| epoch   9 |  2200/   18 batches | ms/batch 64.96 | loss  0.20372\n",
      "| epoch   9 |  2300/   18 batches | ms/batch 64.47 | loss  0.20066\n",
      "| epoch   9 |   100/   18 batches | ms/batch 65.50 | loss  0.17746\n",
      "| epoch   9 |   200/   18 batches | ms/batch 64.62 | loss  0.17522\n",
      "| epoch   9 |   300/   18 batches | ms/batch 64.72 | loss  0.17725\n",
      "| epoch   9 |   400/   18 batches | ms/batch 64.66 | loss  0.16693\n",
      "| epoch   9 |   500/   18 batches | ms/batch 64.70 | loss  0.16815\n",
      "| epoch   9 |   600/   18 batches | ms/batch 65.35 | loss  0.15772\n",
      "| epoch   9 |   700/   18 batches | ms/batch 64.96 | loss  0.15925\n",
      "| epoch   9 |   800/   18 batches | ms/batch 65.56 | loss  0.17023\n",
      "| epoch   9 |   900/   18 batches | ms/batch 65.69 | loss  0.17200\n",
      "| epoch   9 |  1000/   18 batches | ms/batch 65.41 | loss  0.16305\n",
      "| epoch   9 |  1100/   18 batches | ms/batch 65.58 | loss  0.16098\n",
      "| epoch   9 |  1200/   18 batches | ms/batch 65.45 | loss  0.15589\n",
      "| epoch   9 |  1300/   18 batches | ms/batch 65.25 | loss  0.16389\n",
      "| epoch   9 |  1400/   18 batches | ms/batch 65.14 | loss  0.15575\n",
      "| epoch   9 |  1500/   18 batches | ms/batch 64.91 | loss  0.15727\n",
      "| epoch   9 |  1600/   18 batches | ms/batch 64.86 | loss  0.16810\n",
      "| epoch   9 |  1700/   18 batches | ms/batch 65.34 | loss  0.16674\n",
      "| epoch   9 |  1800/   18 batches | ms/batch 65.25 | loss  0.16135\n",
      "| epoch   9 |  1900/   18 batches | ms/batch 65.06 | loss  0.16690\n",
      "| epoch   9 |  2000/   18 batches | ms/batch 65.16 | loss  0.15846\n",
      "| epoch   9 |  2100/   18 batches | ms/batch 105.67 | loss  0.16384\n",
      "| epoch   9 |  2200/   18 batches | ms/batch 64.51 | loss  0.15562\n",
      "| epoch   9 |  2300/   18 batches | ms/batch 64.59 | loss  0.15752\n",
      "syn mse 0.1792159282898053\n",
      "sen_mse 0.08483421701324412\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |   100/   18 batches | ms/batch 64.57 | loss  0.21813\n",
      "| epoch  10 |   200/   18 batches | ms/batch 64.27 | loss  0.20758\n",
      "| epoch  10 |   300/   18 batches | ms/batch 64.53 | loss  0.20106\n",
      "| epoch  10 |   400/   18 batches | ms/batch 64.71 | loss  0.20726\n",
      "| epoch  10 |   500/   18 batches | ms/batch 64.80 | loss  0.20495\n",
      "| epoch  10 |   600/   18 batches | ms/batch 64.95 | loss  0.20507\n",
      "| epoch  10 |   700/   18 batches | ms/batch 65.41 | loss  0.20342\n",
      "| epoch  10 |   800/   18 batches | ms/batch 65.08 | loss  0.20039\n",
      "| epoch  10 |   900/   18 batches | ms/batch 64.96 | loss  0.19890\n",
      "| epoch  10 |  1000/   18 batches | ms/batch 65.00 | loss  0.19831\n",
      "| epoch  10 |  1100/   18 batches | ms/batch 64.36 | loss  0.21009\n",
      "| epoch  10 |  1200/   18 batches | ms/batch 64.30 | loss  0.20507\n",
      "| epoch  10 |  1300/   18 batches | ms/batch 64.31 | loss  0.19912\n",
      "| epoch  10 |  1400/   18 batches | ms/batch 64.31 | loss  0.19697\n",
      "| epoch  10 |  1500/   18 batches | ms/batch 64.23 | loss  0.20058\n",
      "| epoch  10 |  1600/   18 batches | ms/batch 65.07 | loss  0.19945\n",
      "| epoch  10 |  1700/   18 batches | ms/batch 64.61 | loss  0.19741\n",
      "| epoch  10 |  1800/   18 batches | ms/batch 64.22 | loss  0.21131\n",
      "| epoch  10 |  1900/   18 batches | ms/batch 64.20 | loss  0.20227\n",
      "| epoch  10 |  2000/   18 batches | ms/batch 64.42 | loss  0.20515\n",
      "| epoch  10 |  2100/   18 batches | ms/batch 64.81 | loss  0.19791\n",
      "| epoch  10 |  2200/   18 batches | ms/batch 65.08 | loss  0.19668\n",
      "| epoch  10 |  2300/   18 batches | ms/batch 64.91 | loss  0.19258\n",
      "| epoch  10 |   100/   18 batches | ms/batch 65.85 | loss  0.17318\n",
      "| epoch  10 |   200/   18 batches | ms/batch 65.01 | loss  0.16894\n",
      "| epoch  10 |   300/   18 batches | ms/batch 64.99 | loss  0.15771\n",
      "| epoch  10 |   400/   18 batches | ms/batch 64.82 | loss  0.16578\n",
      "| epoch  10 |   500/   18 batches | ms/batch 64.90 | loss  0.16214\n",
      "| epoch  10 |   600/   18 batches | ms/batch 64.92 | loss  0.15323\n",
      "| epoch  10 |   700/   18 batches | ms/batch 64.91 | loss  0.15939\n",
      "| epoch  10 |   800/   18 batches | ms/batch 64.90 | loss  0.16035\n",
      "| epoch  10 |   900/   18 batches | ms/batch 64.88 | loss  0.15966\n",
      "| epoch  10 |  1000/   18 batches | ms/batch 64.61 | loss  0.16225\n",
      "| epoch  10 |  1100/   18 batches | ms/batch 64.30 | loss  0.15931\n",
      "| epoch  10 |  1200/   18 batches | ms/batch 64.44 | loss  0.15672\n",
      "| epoch  10 |  1300/   18 batches | ms/batch 64.76 | loss  0.16257\n",
      "| epoch  10 |  1400/   18 batches | ms/batch 64.44 | loss  0.16916\n",
      "| epoch  10 |  1500/   18 batches | ms/batch 64.44 | loss  0.16744\n",
      "| epoch  10 |  1600/   18 batches | ms/batch 64.48 | loss  0.16618\n",
      "| epoch  10 |  1700/   18 batches | ms/batch 64.53 | loss  0.16615\n",
      "| epoch  10 |  1800/   18 batches | ms/batch 64.53 | loss  0.16116\n",
      "| epoch  10 |  1900/   18 batches | ms/batch 64.49 | loss  0.16814\n",
      "| epoch  10 |  2000/   18 batches | ms/batch 64.63 | loss  0.15936\n",
      "| epoch  10 |  2100/   18 batches | ms/batch 64.91 | loss  0.15181\n",
      "| epoch  10 |  2200/   18 batches | ms/batch 64.71 | loss  0.16529\n",
      "| epoch  10 |  2300/   18 batches | ms/batch 64.79 | loss  0.16301\n",
      "syn mse 0.1823674640752666\n",
      "sen_mse 0.08565471370677592\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "try:\n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        training(False, train_loader)\n",
    "        training(True, train_loader)\n",
    "        evaluate(test_loader)\n",
    "        print('-'*89)\n",
    "except KeyboardInterrupt:\n",
    "    print('-'*89)\n",
    "    print('Existing from training early')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model save\n",
    "torch.save(model.state_dict(), data_path+'exp4-id-feat-gene30-ALMANAC.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comb(\n",
       "  (drugEncoder): DrugEncoder(\n",
       "    (embed_comp): Embedding(48, 48, padding_idx=0)\n",
       "    (encoderlayer): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=48, out_features=48, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=48, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=48, bias=True)\n",
       "      (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=48, out_features=48, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=48, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=48, bias=True)\n",
       "          (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dense_fp): Linear(in_features=167, out_features=32, bias=True)\n",
       "    (dense_gene): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (conv): Conv2d(1, 1, kernel_size=(1, 48), stride=(1, 1))\n",
       "    (FC2): FC2(\n",
       "      (bn): BatchNorm1d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc1): Linear(in_features=352, out_features=176, bias=True)\n",
       "      (fc2): Linear(in_features=176, out_features=64, bias=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (cellEncoder): CellEncoder(\n",
       "    (embed_ds): Embedding(42, 42, padding_idx=3)\n",
       "    (dense_gene): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (FC2): FC2(\n",
       "      (bn): BatchNorm1d(106, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc1): Linear(in_features=106, out_features=53, bias=True)\n",
       "      (fc2): Linear(in_features=53, out_features=64, bias=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc_syn): FC2(\n",
       "    (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc1): Linear(in_features=192, out_features=96, bias=True)\n",
       "    (fc2): Linear(in_features=96, out_features=1, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (fc_ri): FC2(\n",
       "    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model load\n",
    "model.load_state_dict(torch.load(data_path+'exp4-id-feat-gene30-ALMANAC.p'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the general model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_score(y_score, y_true, k):\n",
    "    \"\"\"\n",
    "        https://www.kaggle.com/davidgasquez/ndcg-scorer\n",
    "        y_true: np.array, size= [n_samples]\n",
    "        y_score: np.array, size=[n_samples]\n",
    "        k: int, rank\n",
    "    \"\"\"\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    \n",
    "    #gain = 2 ** y_true -1\n",
    "    gain = y_true \n",
    "    \n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gain/discounts)\n",
    "\n",
    "def evaluate_accuracy(data_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    syn_all=[]\n",
    "    syn_true_all=[]\n",
    "    ri1_all=[]\n",
    "    ri1_true_all=[]\n",
    "    ri2_all=[]\n",
    "    ri2_true_all=[]\n",
    "    \n",
    "    #loss\n",
    "    with torch.no_grad():\n",
    "        for iteration, sample in enumerate(data_loader):\n",
    "            d1=Variable(sample['d1'])\n",
    "            d1_fp = Variable(sample['d1_fp'].float())\n",
    "            d1_sm = Variable(sample['d1_sm'])\n",
    "            d1_gn = Variable(sample['d1_gn'].float())\n",
    "\n",
    "            d2=Variable(sample['d2'])\n",
    "            d2_fp = Variable(sample['d2_fp'].float())\n",
    "            d2_sm = Variable(sample['d2_sm'])\n",
    "            d2_gn = Variable(sample['d2_gn'].float())\n",
    "\n",
    "            cell = Variable(sample['cell'])\n",
    "            c_ts = Variable(sample['c_ts'])\n",
    "            c_ds = Variable(sample['c_ds'])\n",
    "            c_gn = Variable(sample['c_gn'].float())\n",
    "\n",
    "            syn_true = Variable(sample['syn'].float())\n",
    "            ri_d1=Variable(sample['ri_d1'])\n",
    "            ri_d2=Variable(sample['ri_d2'])\n",
    "\n",
    "\n",
    "            if cuda:\n",
    "                d1=d1.cuda()\n",
    "                d1_fp=d1_fp.cuda()\n",
    "                d1_sm=d1_sm.cuda()\n",
    "                d1_gn=d1_gn.cuda()\n",
    "\n",
    "                d2=d2.cuda()\n",
    "                d2_fp=d2_fp.cuda()\n",
    "                d2_sm=d2_sm.cuda()\n",
    "                d2_gn=d2_gn.cuda()\n",
    "\n",
    "                cell=cell.cuda()\n",
    "                c_ts=c_ts.cuda()\n",
    "                c_ds=c_ds.cuda()\n",
    "                c_gn=c_gn.cuda()\n",
    "\n",
    "\n",
    "            syn,ri1,ri2 = model((d1, d1_fp, d1_sm, d1_gn), (d2, d2_fp, d2_sm, d2_gn), (cell, c_ts,c_ds,c_gn) )\n",
    "            \n",
    "            syn_all.append(syn.data.cpu().numpy())\n",
    "            syn_true_all.append(syn_true.numpy())\n",
    "            \n",
    "            ri1_all.append(ri1.data.cpu().numpy())\n",
    "            ri1_true_all.append(ri_d1.numpy())\n",
    "            \n",
    "            ri2_all.append(ri2.data.cpu().numpy())\n",
    "            ri2_true_all.append(ri_d2.numpy())\n",
    "            \n",
    "    return syn_all, syn_true_all, ri1_all, ri1_true_all, ri2_all, ri2_true_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate synergy prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_all, syn_true_all, ri1_all, ri1_true_all, ri2_all, ri2_true_all= evaluate_accuracy(test_loader)\n",
    "\n",
    "syn_all= [s.item() for syn in syn_all for s in syn]\n",
    "syn_true_all = [s for syn in syn_true_all for s in syn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NDCG\n",
    "dcg_score(syn_all,syn_true_all, k=20)/dcg_score(syn_true_all,syn_true_all, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8597005380338557"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUPRC\n",
    "metrics.average_precision_score(syn_true_all,  1/(1 + np.exp(-np.array(syn_all))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9626759388821085"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUROC\n",
    "metrics.roc_auc_score(syn_true_all,  1/(1 + np.exp(-np.array(syn_all))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate sensitivity prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri1_all= [r.item() for ri in ri1_all for r in ri]\n",
    "ri1_true_all = [r for ri in ri1_true_all for r in ri]\n",
    "\n",
    "ri2_all= [r.item() for ri in ri2_all for r in ri]\n",
    "ri2_true_all = [r for ri in ri2_true_all for r in ri]\n",
    "\n",
    "ri_all=ri1_all+ri2_all\n",
    "ri_true_all=ri1_true_all+ri2_true_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3387952081956902"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NDCG\n",
    "dcg_score(ri_all,ri_true_all, k=20)/dcg_score(ri_true_all,ri_true_all, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8651108739972198"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUC\n",
    "metrics.roc_auc_score(ri_true_all,  1/(1 + np.exp(-np.array(ri_all))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer the general model to specific model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to boost a bit more with general model's test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  10 |   100/   18 batches | ms/batch 62.44 | loss  0.21246\n",
      "| epoch  10 |   200/   18 batches | ms/batch 62.74 | loss  0.20853\n",
      "| epoch  10 |   300/   18 batches | ms/batch 63.19 | loss  0.20654\n",
      "| epoch  10 |   400/   18 batches | ms/batch 63.33 | loss  0.20849\n",
      "| epoch  10 |   500/   18 batches | ms/batch 64.04 | loss  0.19935\n",
      "| epoch  10 |   100/   18 batches | ms/batch 64.36 | loss  0.16313\n",
      "| epoch  10 |   200/   18 batches | ms/batch 63.71 | loss  0.16199\n",
      "| epoch  10 |   300/   18 batches | ms/batch 64.42 | loss  0.16235\n",
      "| epoch  10 |   400/   18 batches | ms/batch 64.95 | loss  0.15352\n",
      "| epoch  10 |   500/   18 batches | ms/batch 64.38 | loss  0.15460\n"
     ]
    }
   ],
   "source": [
    "#Use major's test set\n",
    "training(False, test_loader)\n",
    "training(True, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the layer's ID that we'd like to fix or free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([48, 48]) True\n",
      "1 torch.Size([144, 48]) True\n",
      "2 torch.Size([144]) True\n",
      "3 torch.Size([48, 48]) True\n",
      "4 torch.Size([48]) True\n",
      "5 torch.Size([2048, 48]) True\n",
      "6 torch.Size([2048]) True\n",
      "7 torch.Size([48, 2048]) True\n",
      "8 torch.Size([48]) True\n",
      "9 torch.Size([48]) True\n",
      "10 torch.Size([48]) True\n",
      "11 torch.Size([48]) True\n",
      "12 torch.Size([48]) True\n",
      "13 torch.Size([144, 48]) True\n",
      "14 torch.Size([144]) True\n",
      "15 torch.Size([48, 48]) True\n",
      "16 torch.Size([48]) True\n",
      "17 torch.Size([2048, 48]) True\n",
      "18 torch.Size([2048]) True\n",
      "19 torch.Size([48, 2048]) True\n",
      "20 torch.Size([48]) True\n",
      "21 torch.Size([48]) True\n",
      "22 torch.Size([48]) True\n",
      "23 torch.Size([48]) True\n",
      "24 torch.Size([48]) True\n",
      "25 torch.Size([32, 167]) True\n",
      "26 torch.Size([32]) True\n",
      "27 torch.Size([32, 64]) True\n",
      "28 torch.Size([32]) True\n",
      "29 torch.Size([1, 1, 1, 48]) True\n",
      "30 torch.Size([1]) True\n",
      "31 torch.Size([352]) True\n",
      "32 torch.Size([352]) True\n",
      "33 torch.Size([176, 352]) True\n",
      "34 torch.Size([176]) True\n",
      "35 torch.Size([64, 176]) True\n",
      "36 torch.Size([64]) True\n",
      "37 torch.Size([42, 42]) True\n",
      "38 torch.Size([64, 128]) True\n",
      "39 torch.Size([64]) True\n",
      "40 torch.Size([106]) True\n",
      "41 torch.Size([106]) True\n",
      "42 torch.Size([53, 106]) True\n",
      "43 torch.Size([53]) True\n",
      "44 torch.Size([64, 53]) True\n",
      "45 torch.Size([64]) True\n",
      "46 torch.Size([192]) True\n",
      "47 torch.Size([192]) True\n",
      "48 torch.Size([96, 192]) True\n",
      "49 torch.Size([96]) True\n",
      "50 torch.Size([1, 96]) True\n",
      "51 torch.Size([1]) True\n",
      "52 torch.Size([128]) True\n",
      "53 torch.Size([128]) True\n",
      "54 torch.Size([64, 128]) True\n",
      "55 torch.Size([64]) True\n",
      "56 torch.Size([1, 64]) True\n",
      "57 torch.Size([1]) True\n"
     ]
    }
   ],
   "source": [
    "for i, param in enumerate(model.parameters()):\n",
    "    print(i, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_after = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, param in enumerate(model.parameters()):\n",
    "    if i>=release_after:\n",
    "        param.requires_grad=True\n",
    "    else:\n",
    "        param.requires_grad=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prostate or bone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_loader_minor=_train_loader_prostate\n",
    "_test_loader_minor=_test_loader_prostate\n",
    "_test_minor=_test_prostate\n",
    "#_train_loader_minor=_train_loader_bone\n",
    "#_test_loader_minor=_test_loader_bone\n",
    "#_test_minor=_test_bone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syn mse 0.23522883967349403\n",
      "sen_mse 0.054807305335998535\n",
      "-----------------------------------------------------------------------------------------\n",
      "syn mse 0.21754811939440274\n",
      "sen_mse 0.05209772837789435\n",
      "-----------------------------------------------------------------------------------------\n",
      "syn mse 0.20951858319734273\n",
      "sen_mse 0.05222006847983912\n",
      "-----------------------------------------------------------------------------------------\n",
      "syn mse 0.20513082805432772\n",
      "sen_mse 0.05404499330018696\n",
      "-----------------------------------------------------------------------------------------\n",
      "syn mse 0.20166143618131938\n",
      "sen_mse 0.05618089123776084\n",
      "-----------------------------------------------------------------------------------------\n",
      "syn mse 0.19788769671791478\n",
      "sen_mse 0.05457201756929096\n",
      "-----------------------------------------------------------------------------------------\n",
      "syn mse 0.19574369882282458\n",
      "sen_mse 0.053817065138565864\n",
      "-----------------------------------------------------------------------------------------\n",
      "syn mse 0.19225268614919563\n",
      "sen_mse 0.053288522519563376\n",
      "-----------------------------------------------------------------------------------------\n",
      "syn mse 0.18987788652118884\n",
      "sen_mse 0.05289835051486367\n",
      "-----------------------------------------------------------------------------------------\n",
      "syn mse 0.1852008668999923\n",
      "sen_mse 0.05182761267611855\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Use minor's train set\n",
    "try:\n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        training(False, _train_loader_minor)\n",
    "        training(True, _train_loader_minor)\n",
    "        evaluate(_test_loader_minor)\n",
    "        print('-'*89)\n",
    "except KeyboardInterrupt:\n",
    "    print('-'*89)\n",
    "    print('Existing from training early')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate synergy prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_all, syn_true_all, ri1_all, ri1_true_all, ri2_all, ri2_true_all= evaluate_accuracy(_test_loader_minor)\n",
    "\n",
    "syn_all= [s.item() for syn in syn_all for s in syn]\n",
    "syn_true_all = [s for syn in syn_true_all for s in syn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NDCG\n",
    "dcg_score(syn_all,syn_true_all, k=20)/dcg_score(syn_true_all,syn_true_all, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9606108567590311"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUROC\n",
    "metrics.roc_auc_score(syn_true_all,  1/(1 + np.exp(-np.array(syn_all))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8047669798951004"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUPRC\n",
    "metrics.average_precision_score(syn_true_all,  1/(1 + np.exp(-np.array(syn_all))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate sensitivity prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri1_all= [r.item() for ri in ri1_all for r in ri]\n",
    "ri1_true_all = [r for ri in ri1_true_all for r in ri]\n",
    "\n",
    "ri2_all= [r.item() for ri in ri2_all for r in ri]\n",
    "ri2_true_all = [r for ri in ri2_true_all for r in ri]\n",
    "\n",
    "ri_all=ri1_all+ri2_all\n",
    "ri_true_all=ri1_true_all+ri2_true_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06922125855611583"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NDCG\n",
    "dcg_score(ri_all,ri_true_all, k=20)/dcg_score(ri_true_all,ri_true_all, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7822307029174376"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUC\n",
    "metrics.roc_auc_score(ri_true_all,  1/(1 + np.exp(-np.array(ri_all))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the top ranked drug combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_all_prob=1/(1 + np.exp(-np.array(syn_all)))\n",
    "order = np.argsort(syn_all_prob)[::-1]\n",
    "syn_true_all_order = np.take(syn_true_all, order[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHEMBL17639 , IXABEPILONE , DU-145 , prostate , c4863 , 0 , 0 , 1.0\n",
      "ELOXATIN (TN) (SANOFI SYNTHELAB) , IXABEPILONE , DU-145 , prostate , c4863 , 0 , 0 , 1.0\n",
      "IMATINIB , IXABEPILONE , DU-145 , prostate , c4863 , 0 , 0 , 1.0\n",
      "ACTINOMYCIN D , IXABEPILONE , PC-3 , prostate , c4863 , 0 , 0 , 1.0\n",
      "PLICAMYCIN , IXABEPILONE , DU-145 , prostate , c4863 , 0 , 0 , 1.0\n",
      "QUINACRINE HYDROCHLORIDE , IXABEPILONE , DU-145 , prostate , c4863 , 0 , 0 , 1.0\n",
      "FLUDARABINE BASE , IXABEPILONE , DU-145 , prostate , c4863 , 0 , 0 , 1.0\n",
      "ELOXATIN (TN) (SANOFI SYNTHELAB) , IXABEPILONE , PC-3 , prostate , c4863 , 0 , 0 , 1.0\n",
      "DOCETAXEL , IXABEPILONE , PC-3 , prostate , c4863 , 0 , 0 , 1.0\n",
      "IMATINIB , IXABEPILONE , PC-3 , prostate , c4863 , 0 , 0 , 1.0\n",
      "PRALATREXATE , IXABEPILONE , DU-145 , prostate , c4863 , 0 , 0 , 1.0\n",
      "LETROZOLE , IXABEPILONE , DU-145 , prostate , c4863 , 0 , 0 , 1.0\n",
      "RUXOLITINIB , CABAZITAXEL , DU-145 , prostate , c4863 , 0 , 0 , 1.0\n",
      "CO-V , IXABEPILONE , DU-145 , prostate , c4863 , 0 , 0 , 1.0\n",
      "HYDROXYUREA , IXABEPILONE , PC-3 , prostate , c4863 , 0 , 0 , 1.0\n",
      "AXITINIB , CABAZITAXEL , DU-145 , prostate , c4863 , 0 , 0 , 1.0\n",
      "CHEMBL17639 , ARSENIC TRIOXIDE , DU-145 , prostate , c4863 , 0 , 0 , 1.0\n",
      "CYCLOPHOSPHAMIDE , BEZ-235 , LNCAP , prostate , c4863 , 0 , 0 , 1.0\n",
      "ACTINOMYCIN D , ARSENIC TRIOXIDE , DU-145 , prostate , c4863 , 0 , 0 , 1.0\n",
      "MK-5108 , TOPOTECAN , LNCAP , prostate , c4863 , 0 , 0 , 1.0\n"
     ]
    }
   ],
   "source": [
    "for k in range(20):\n",
    "    comb=_test_minor[order[k]]\n",
    "    print(codes['drugs'].idx2item[comb['d1']], ',', \n",
    "          codes['drugs'].idx2item[comb['d2']], ',', \n",
    "          codes['cell'].idx2item[comb['cell']],  ',', \n",
    "          codes['tissue'].idx2item[comb['c_ts']],  ',',\n",
    "          codes['disease'].idx2item[comb['c_ds']], ',', \n",
    "          comb['ri_d1'], ',',\n",
    "          comb['ri_d2'], ',',\n",
    "          syn_true_all_order[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
